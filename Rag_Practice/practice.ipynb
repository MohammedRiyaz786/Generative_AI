{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Using cached pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "def extract_with_pdf(path):\n",
    "    text =\"\"\n",
    "    with pdfplumber.open(path) as pdfreader:\n",
    "        for page in pdfreader.pages:\n",
    "            text+=page.extract_text() or \"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extracted=extract_with_pdf(r\"D:\\waste for git\\Generative_AI\\Rag\\attention all you need.pdf\")\n",
    "#print(text_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Langchain in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (3.10.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.8 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (0.3.8)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (0.1.131)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from Langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.8->Langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.8->Langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.8->Langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->Langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->Langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->Langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->Langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->Langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->Langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->Langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->Langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->Langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->Langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->Langchain) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->Langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->Langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->Langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->Langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->Langchain) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attention Is All You Need\\nAshishVaswani∗ NoamShazeer∗ NikiParmar∗ JakobUszkoreit∗\\nGoogleBrain GoogleBrain GoogleResearch GoogleResearch\\navaswani@google.com noam@google.com nikip@google.com usz@google.com\\nLlionJones∗ AidanN.Gomez∗ † ŁukaszKaiser∗\\nGoogleResearch UniversityofToronto GoogleBrain\\nllion@google.com aidan@cs.toronto.edu lukaszkaiser@google.com\\nIlliaPolosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThedominantsequencetransductionmodelsarebasedoncomplexrecurrentor', 'convolutionalneuralnetworksthatincludeanencoderandadecoder. Thebest\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbasedsolelyonattentionmechanisms,dispensingwithrecurrenceandconvolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbesuperiorinqualitywhilebeingmoreparallelizableandrequiringsignificantly', 'less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles,byover2BLEU.OntheWMT2014English-to-Frenchtranslationtask,\\nourmodelestablishesanewsingle-modelstate-of-the-artBLEUscoreof41.0after\\ntrainingfor3.5daysoneightGPUs,asmallfractionofthetrainingcostsofthe\\nbestmodelsfromtheliterature.\\n1 Introduction\\nRecurrentneuralnetworks,longshort-termmemory[12]andgatedrecurrent[7]neuralnetworks', 'inparticular,havebeenfirmlyestablishedasstateoftheartapproachesinsequencemodelingand\\ntransductionproblemssuchaslanguagemodelingandmachinetranslation[29,2,5]. Numerous\\neffortshavesincecontinuedtopushtheboundariesofrecurrentlanguagemodelsandencoder-decoder\\narchitectures[31,21,13].\\n∗Equalcontribution.Listingorderisrandom.JakobproposedreplacingRNNswithself-attentionandstarted\\ntheefforttoevaluatethisidea.Ashish,withIllia,designedandimplementedthefirstTransformermodelsand', 'hasbeencruciallyinvolvedineveryaspectofthiswork.Noamproposedscaleddot-productattention,multi-head\\nattentionandtheparameter-freepositionrepresentationandbecametheotherpersoninvolvedinnearlyevery\\ndetail.Nikidesigned,implemented,tunedandevaluatedcountlessmodelvariantsinouroriginalcodebaseand\\ntensor2tensor.Llionalsoexperimentedwithnovelmodelvariants,wasresponsibleforourinitialcodebase,and\\nefficientinferenceandvisualizations.LukaszandAidanspentcountlesslongdaysdesigningvariouspartsofand', 'implementingtensor2tensor,replacingourearliercodebase,greatlyimprovingresultsandmassivelyaccelerating\\nourresearch.\\n†WorkperformedwhileatGoogleBrain.\\n‡WorkperformedwhileatGoogleResearch.\\n31stConferenceonNeuralInformationProcessingSystems(NIPS2017),LongBeach,CA,USA.Recurrentmodelstypicallyfactorcomputationalongthesymbolpositionsoftheinputandoutput\\nsequences. Aligningthepositionstostepsincomputationtime,theygenerateasequenceofhidden', 'statesh ,asafunctionoftheprevioushiddenstateh andtheinputforpositiont. Thisinherently\\nt t−1\\nsequentialnatureprecludesparallelizationwithintrainingexamples,whichbecomescriticalatlonger\\nsequencelengths,asmemoryconstraintslimitbatchingacrossexamples. Recentworkhasachieved\\nsignificantimprovementsincomputationalefficiencythroughfactorizationtricks[18]andconditional\\ncomputation[26],whilealsoimprovingmodelperformanceincaseofthelatter. Thefundamental\\nconstraintofsequentialcomputation,however,remains.', 'Attentionmechanismshavebecomeanintegralpartofcompellingsequencemodelingandtransduc-\\ntionmodelsinvarioustasks,allowingmodelingofdependencieswithoutregardtotheirdistancein\\ntheinputoroutputsequences[2,16]. Inallbutafewcases[22],however,suchattentionmechanisms\\nareusedinconjunctionwitharecurrentnetwork.\\nInthisworkweproposetheTransformer,amodelarchitectureeschewingrecurrenceandinstead\\nrelyingentirelyonanattentionmechanismtodrawglobaldependenciesbetweeninputandoutput.', 'TheTransformerallowsforsignificantlymoreparallelizationandcanreachanewstateoftheartin\\ntranslationqualityafterbeingtrainedforaslittleastwelvehoursoneightP100GPUs.\\n2 Background\\nThegoalofreducingsequentialcomputationalsoformsthefoundationoftheExtendedNeuralGPU\\n[20],ByteNet[15]andConvS2S[8],allofwhichuseconvolutionalneuralnetworksasbasicbuilding\\nblock,computinghiddenrepresentationsinparallelforallinputandoutputpositions.Inthesemodels,', 'thenumberofoperationsrequiredtorelatesignalsfromtwoarbitraryinputoroutputpositionsgrows\\ninthedistancebetweenpositions,linearlyforConvS2SandlogarithmicallyforByteNet. Thismakes\\nit more difficult to learn dependencies between distant positions [11]. In the Transformer this is\\nreducedtoaconstantnumberofoperations, albeitatthecostofreducedeffectiveresolutiondue\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribedinsection3.2.', 'describedinsection3.2.\\nSelf-attention,sometimescalledintra-attentionisanattentionmechanismrelatingdifferentpositions\\nofasinglesequenceinordertocomputearepresentationofthesequence. Self-attentionhasbeen\\nusedsuccessfullyinavarietyoftasksincludingreadingcomprehension,abstractivesummarization,\\ntextualentailmentandlearningtask-independentsentencerepresentations[4,22,23,19].\\nEnd-to-endmemorynetworksarebasedonarecurrentattentionmechanisminsteadofsequence-', 'alignedrecurrenceandhavebeenshowntoperformwellonsimple-languagequestionansweringand\\nlanguagemodelingtasks[28].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirelyonself-attentiontocomputerepresentationsofitsinputandoutputwithoutusingsequence-\\nalignedRNNsorconvolution. Inthefollowingsections,wewilldescribetheTransformer,motivate\\nself-attentionanddiscussitsadvantagesovermodelssuchas[14,15]and[8].\\n3 ModelArchitecture', '3 ModelArchitecture\\nMostcompetitiveneuralsequencetransductionmodelshaveanencoder-decoderstructure[5,2,29].\\nHere, the encoder maps an input sequence of symbol representations (x ,...,x ) to a sequence\\n1 n\\nof continuous representations z = (z ,...,z ). Given z, the decoder then generates an output\\n1 n\\nsequence(y ,...,y )ofsymbolsoneelementatatime. Ateachstepthemodelisauto-regressive\\n1 m\\n[9],consumingthepreviouslygeneratedsymbolsasadditionalinputwhengeneratingthenext.', 'TheTransformerfollowsthisoverallarchitectureusingstackedself-attentionandpoint-wise,fully\\nconnectedlayersforboththeencoderanddecoder,shownintheleftandrighthalvesofFigure1,\\nrespectively.\\n3.1 EncoderandDecoderStacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. Thefirstisamulti-headself-attentionmechanism,andthesecondisasimple,position-\\n2Figure1: TheTransformer-modelarchitecture.', '2Figure1: TheTransformer-modelarchitecture.\\nwisefullyconnectedfeed-forwardnetwork. Weemployaresidualconnection[10]aroundeachof\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x+Sublayer(x)),whereSublayer(x)isthefunctionimplementedbythesub-layer\\nitself. Tofacilitatetheseresidualconnections,allsub-layersinthemodel,aswellastheembedding\\nlayers,produceoutputsofdimensiond =512.\\nmodel', 'layers,produceoutputsofdimensiond =512.\\nmodel\\nDecoder: ThedecoderisalsocomposedofastackofN =6identicallayers. Inadditiontothetwo\\nsub-layersineachencoderlayer,thedecoderinsertsathirdsub-layer,whichperformsmulti-head\\nattentionovertheoutputoftheencoderstack. Similartotheencoder,weemployresidualconnections\\naroundeachofthesub-layers,followedbylayernormalization. Wealsomodifytheself-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This', 'masking,combinedwithfactthattheoutputembeddingsareoffsetbyoneposition,ensuresthatthe\\npredictionsforpositionicandependonlyontheknownoutputsatpositionslessthani.\\n3.2 Attention\\nAnattentionfunctioncanbedescribedasmappingaqueryandasetofkey-valuepairstoanoutput,\\nwherethequery,keys,values,andoutputareallvectors. Theoutputiscomputedasaweightedsum\\nofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthe\\nquerywiththecorrespondingkey.\\n3.2.1 ScaledDot-ProductAttention', '3.2.1 ScaledDot-ProductAttention\\nWecallourparticularattention\"ScaledDot-ProductAttention\"(Figure2). Theinputconsistsof\\nqueriesandkeysofdimensiond ,andvaluesofdimensiond . Wecomputethedotproductsofthe\\nk v\\n3ScaledDot-ProductAttention Multi-HeadAttention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattentionlayersrunninginparallel.\\n√\\nquerywithallkeys,divideeachby d ,andapplyasoftmaxfunctiontoobtaintheweightsonthe\\nk\\nvalues.', 'k\\nvalues.\\nInpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogether\\nintoamatrixQ. ThekeysandvaluesarealsopackedtogetherintomatricesK andV. Wecompute\\nthematrixofoutputsas:\\nQKT\\nAttention(Q,K,V)=softmax( √ )V (1)\\nd\\nk\\nThetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-\\nplicative)attention. Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactor', 'of √1 . Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith\\ndk\\nasinglehiddenlayer. Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionis\\nmuchfasterandmorespace-efficientinpractice,sinceitcanbeimplementedusinghighlyoptimized\\nmatrixmultiplicationcode.\\nWhileforsmallvaluesofd thetwomechanismsperformsimilarly,additiveattentionoutperforms\\nk\\ndotproductattentionwithoutscalingforlargervaluesofd [3]. Wesuspectthatforlargevaluesof\\nk', 'k\\nd ,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithas\\nk\\nextremelysmallgradients4. Tocounteractthiseffect,wescalethedotproductsby √1 .\\ndk\\n3.2.2 Multi-HeadAttention\\nInsteadofperformingasingleattentionfunctionwithd -dimensionalkeys,valuesandqueries,\\nmodel\\nwefounditbeneficialtolinearlyprojectthequeries,keysandvalueshtimeswithdifferent,learned\\nlinearprojectionstod ,d andd dimensions,respectively. Oneachoftheseprojectedversionsof\\nk k v', 'k k v\\nqueries,keysandvalueswethenperformtheattentionfunctioninparallel,yieldingd -dimensional\\nv\\noutput values. These are concatenated and once again projected, resulting in the final values, as\\ndepictedinFigure2.\\nMulti-headattentionallowsthemodeltojointlyattendtoinformationfromdifferentrepresentation\\nsubspacesatdifferentpositions. Withasingleattentionhead,averaginginhibitsthis.\\n4Toillustratewhythedotproductsgetlarge,assumethatthecomponentsofqandkareindependentrandom', 'variableswithmean0andvariance1.Thentheirdotproduct,q·k=(cid:80)dk\\nq k ,hasmean0andvarianced .\\ni=1 i i k\\n4MultiHead(Q,K,V)=Concat(head ,...,head )WO\\n1 h\\nwherehead =Attention(QWQ,KWK,VWV)\\ni i i i\\nWheretheprojectionsareparametermatricesWQ ∈Rdmodel×dk,WK ∈Rdmodel×dk,WV ∈Rdmodel×dv\\ni i i\\nandWO ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\nd =d =d /h=64. Duetothereduceddimensionofeachhead,thetotalcomputationalcost\\nk v model', 'k v model\\nissimilartothatofsingle-headattentionwithfulldimensionality.\\n3.2.3 ApplicationsofAttentioninourModel\\nTheTransformerusesmulti-headattentioninthreedifferentways:\\n• In\"encoder-decoderattention\"layers,thequeriescomefromthepreviousdecoderlayer,\\nandthememorykeysandvaluescomefromtheoutputoftheencoder. Thisallowsevery\\npositioninthedecodertoattendoverallpositionsintheinputsequence. Thismimicsthe\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31,2,8].', '[31,2,8].\\n• Theencodercontainsself-attentionlayers. Inaself-attentionlayerallofthekeys,values\\nandqueriescomefromthesameplace,inthiscase,theoutputofthepreviouslayerinthe\\nencoder. Eachpositionintheencodercanattendtoallpositionsinthepreviouslayerofthe\\nencoder.\\n• Similarly,self-attentionlayersinthedecoderalloweachpositioninthedecodertoattendto\\nallpositionsinthedecoderuptoandincludingthatposition. Weneedtopreventleftward', 'informationflowinthedecodertopreservetheauto-regressiveproperty. Weimplementthis\\ninsideofscaleddot-productattentionbymaskingout(settingto−∞)allvaluesintheinput\\nofthesoftmaxwhichcorrespondtoillegalconnections. SeeFigure2.\\n3.3 Position-wiseFeed-ForwardNetworks\\nInadditiontoattentionsub-layers,eachofthelayersinourencoderanddecodercontainsafully\\nconnectedfeed-forwardnetwork,whichisappliedtoeachpositionseparatelyandidentically. This\\nconsistsoftwolineartransformationswithaReLUactivationinbetween.', 'FFN(x)=max(0,xW +b )W +b (2)\\n1 1 2 2\\nWhilethelineartransformationsarethesameacrossdifferentpositions,theyusedifferentparameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is d = 512, and the inner-layer has dimensionality\\nmodel\\nd =2048.\\nff\\n3.4 EmbeddingsandSoftmax\\nSimilarlytoothersequencetransductionmodels,weuselearnedembeddingstoconverttheinput', 'tokensandoutputtokenstovectorsofdimensiond . Wealsousetheusuallearnedlineartransfor-\\nmodel\\nmationandsoftmaxfunctiontoconvertthedecoderoutputtopredictednext-tokenprobabilities. In\\nourmodel,wesharethesameweightmatrixbetweenthetwoembeddinglayersandthepre-√softmax\\nlineartransformation,similarto[24]. Intheembeddinglayers,wemultiplythoseweightsby d .\\nmodel\\n3.5 PositionalEncoding\\nSinceourmodelcontainsnorecurrenceandnoconvolution,inorderforthemodeltomakeuseofthe', 'orderofthesequence,wemustinjectsomeinformationabouttherelativeorabsolutepositionofthe\\ntokensinthesequence. Tothisend,weadd\"positionalencodings\"totheinputembeddingsatthe\\n5Table1: Maximumpathlengths,per-layercomplexityandminimumnumberofsequentialoperations\\nfordifferentlayertypes. nisthesequencelength,distherepresentationdimension,kisthekernel\\nsizeofconvolutionsandrthesizeoftheneighborhoodinrestrictedself-attention.\\nLayerType ComplexityperLayer Sequential MaximumPathLength\\nOperations', 'Operations\\nSelf-Attention O(n2·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(log (n))\\nk\\nSelf-Attention(restricted) O(r·n·d) O(1) O(n/r)\\nbottomsoftheencoderanddecoderstacks. Thepositionalencodingshavethesamedimensiond\\nmodel\\nastheembeddings,sothatthetwocanbesummed. Therearemanychoicesofpositionalencodings,\\nlearnedandfixed[8].\\nInthiswork,weusesineandcosinefunctionsofdifferentfrequencies:\\nPE =sin(pos/100002i/dmodel)\\n(pos,2i)\\nPE =cos(pos/100002i/dmodel)\\n(pos,2i+1)', '(pos,2i)\\nPE =cos(pos/100002i/dmodel)\\n(pos,2i+1)\\nwhereposisthepositionandiisthedimension. Thatis,eachdimensionofthepositionalencoding\\ncorrespondstoasinusoid. Thewavelengthsformageometricprogressionfrom2πto10000·2π. We\\nchosethisfunctionbecausewehypothesizeditwouldallowthemodeltoeasilylearntoattendby\\nrelativepositions,sinceforanyfixedoffsetk,PE canberepresentedasalinearfunctionof\\npos+k\\nPE .\\npos\\nWealsoexperimentedwithusinglearnedpositionalembeddings[8]instead,andfoundthatthetwo', 'versionsproducednearlyidenticalresults(seeTable3row(E)).Wechosethesinusoidalversion\\nbecauseitmayallowthemodeltoextrapolatetosequencelengthslongerthantheonesencountered\\nduringtraining.\\n4 WhySelf-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntionallayerscommonlyusedformappingonevariable-lengthsequenceofsymbolrepresentations\\n(x ,...,x ) to another sequence of equal length (z ,...,z ), with x ,z ∈ Rd, such as a hidden\\n1 n 1 n i i', '1 n 1 n i i\\nlayerinatypicalsequencetransductionencoderordecoder. Motivatingouruseofself-attentionwe\\nconsiderthreedesiderata.\\nOneisthetotalcomputationalcomplexityperlayer. Anotheristheamountofcomputationthatcan\\nbeparallelized,asmeasuredbytheminimumnumberofsequentialoperationsrequired.\\nThethirdisthepathlengthbetweenlong-rangedependenciesinthenetwork. Learninglong-range\\ndependenciesisakeychallengeinmanysequencetransductiontasks. Onekeyfactoraffectingthe', 'abilitytolearnsuchdependenciesisthelengthofthepathsforwardandbackwardsignalshaveto\\ntraverseinthenetwork. Theshorterthesepathsbetweenanycombinationofpositionsintheinput\\nandoutputsequences,theeasieritistolearnlong-rangedependencies[11]. Hencewealsocompare\\nthemaximumpathlengthbetweenanytwoinputandoutputpositionsinnetworkscomposedofthe\\ndifferentlayertypes.\\nAsnotedinTable1,aself-attentionlayerconnectsallpositionswithaconstantnumberofsequentially', 'executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputationalcomplexity,self-attentionlayersarefasterthanrecurrentlayerswhenthesequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentencerepresentationsusedbystate-of-the-artmodelsinmachinetranslations,suchasword-piece\\n[31]andbyte-pair[25]representations. Toimprovecomputationalperformancefortasksinvolving', 'verylongsequences,self-attentioncouldberestrictedtoconsideringonlyaneighborhoodofsizerin\\n6theinputsequencecenteredaroundtherespectiveoutputposition. Thiswouldincreasethemaximum\\npathlengthtoO(n/r). Weplantoinvestigatethisapproachfurtherinfuturework.\\nAsingleconvolutionallayerwithkernelwidthk <ndoesnotconnectallpairsofinputandoutput\\npositions. DoingsorequiresastackofO(n/k)convolutionallayersinthecaseofcontiguouskernels,', 'orO(log (n))inthecaseofdilatedconvolutions[15], increasingthelengthofthelongestpaths\\nk\\nbetweenanytwopositionsinthenetwork. Convolutionallayersaregenerallymoreexpensivethan\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, toO(k·n·d+n·d2). Evenwithk = n, however, thecomplexityofaseparable\\nconvolutionisequaltothecombinationofaself-attentionlayerandapoint-wisefeed-forwardlayer,\\ntheapproachwetakeinourmodel.', 'theapproachwetakeinourmodel.\\nAssidebenefit,self-attentioncouldyieldmoreinterpretablemodels.Weinspectattentiondistributions\\nfromourmodelsandpresentanddiscussexamplesintheappendix. Notonlydoindividualattention\\nheadsclearlylearntoperformdifferenttasks,manyappeartoexhibitbehaviorrelatedtothesyntactic\\nandsemanticstructureofthesentences.\\n5 Training\\nThissectiondescribesthetrainingregimeforourmodels.\\n5.1 TrainingDataandBatching', '5.1 TrainingDataandBatching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentencepairs. Sentenceswereencodedusingbyte-pairencoding[3],whichhasasharedsource-\\ntargetvocabularyofabout37000tokens. ForEnglish-French,weusedthesignificantlylargerWMT\\n2014English-Frenchdatasetconsistingof36Msentencesandsplittokensintoa32000word-piece\\nvocabulary[31].Sentencepairswerebatchedtogetherbyapproximatesequencelength.Eachtraining', 'batchcontainedasetofsentencepairscontainingapproximately25000sourcetokensand25000\\ntargettokens.\\n5.2 HardwareandSchedule\\nWetrainedourmodelsononemachinewith8NVIDIAP100GPUs. Forourbasemodelsusing\\nthehyperparametersdescribedthroughoutthepaper,eachtrainingsteptookabout0.4seconds. We\\ntrainedthebasemodelsforatotalof100,000stepsor12hours. Forourbigmodels,(describedonthe\\nbottomlineoftable3),steptimewas1.0seconds. Thebigmodelsweretrainedfor300,000steps\\n(3.5days).\\n5.3 Optimizer', '(3.5days).\\n5.3 Optimizer\\nWeusedtheAdamoptimizer[17]withβ =0.9,β =0.98and(cid:15)=10−9. Wevariedthelearning\\n1 2\\nrateoverthecourseoftraining,accordingtotheformula:\\nlrate=d−0.5 ·min(step_num−0.5,step_num·warmup_steps−1.5) (3)\\nmodel\\nThiscorrespondstoincreasingthelearningratelinearlyforthefirstwarmup_stepstrainingsteps,\\nanddecreasingitthereafterproportionallytotheinversesquarerootofthestepnumber. Weused\\nwarmup_steps=4000.\\n5.4 Regularization\\nWeemploythreetypesofregularizationduringtraining:', 'Weemploythreetypesofregularizationduringtraining:\\nResidualDropout Weapplydropout[27]totheoutputofeachsub-layer,beforeitisaddedtothe\\nsub-layerinputandnormalized. Inaddition,weapplydropouttothesumsoftheembeddingsandthe\\npositionalencodingsinboththeencoderanddecoderstacks. Forthebasemodel,weusearateof\\nP =0.1.\\ndrop\\n7Table2: TheTransformerachievesbetterBLEUscoresthanpreviousstate-of-the-artmodelsonthe\\nEnglish-to-GermanandEnglish-to-Frenchnewstest2014testsatafractionofthetrainingcost.', 'BLEU TrainingCost(FLOPs)\\nModel\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet[15] 23.75\\nDeep-Att+PosUnk[32] 39.2 1.0·1020\\nGNMT+RL[31] 24.6 39.92 2.3·1019 1.4·1020\\nConvS2S[8] 25.16 40.46 9.6·1018 1.5·1020\\nMoE[26] 26.03 40.56 2.0·1019 1.2·1020\\nDeep-Att+PosUnkEnsemble[32] 40.4 8.0·1020\\nGNMT+RLEnsemble[31] 26.30 41.16 1.8·1020 1.1·1021\\nConvS2SEnsemble[8] 26.36 41.29 7.7·1019 1.2·1021\\nTransformer(basemodel) 27.3 38.1 3.3·1018\\nTransformer(big) 28.4 41.0 2.3·1019', 'Transformer(big) 28.4 41.0 2.3·1019\\nLabelSmoothing Duringtraining,weemployedlabelsmoothingofvalue(cid:15) = 0.1[30]. This\\nls\\nhurtsperplexity,asthemodellearnstobemoreunsure,butimprovesaccuracyandBLEUscore.\\n6 Results\\n6.1 MachineTranslation\\nOntheWMT2014English-to-Germantranslationtask,thebigtransformermodel(Transformer(big)\\ninTable2)outperformsthebestpreviouslyreportedmodels(includingensembles)bymorethan2.0\\nBLEU,establishinganewstate-of-the-artBLEUscoreof28.4. Theconfigurationofthismodelis', 'listedinthebottomlineofTable3. Trainingtook3.5dayson8P100GPUs. Evenourbasemodel\\nsurpassesallpreviouslypublishedmodelsandensembles,atafractionofthetrainingcostofanyof\\nthecompetitivemodels.\\nOntheWMT2014English-to-Frenchtranslationtask,ourbigmodelachievesaBLEUscoreof41.0,\\noutperformingallofthepreviouslypublishedsinglemodels,atlessthan1/4thetrainingcostofthe\\npreviousstate-of-the-artmodel. TheTransformer(big)modeltrainedforEnglish-to-Frenchused\\ndropoutrateP =0.1,insteadof0.3.\\ndrop', 'dropoutrateP =0.1,insteadof0.3.\\ndrop\\nForthebasemodels,weusedasinglemodelobtainedbyaveragingthelast5checkpoints,which\\nwerewrittenat10-minuteintervals. Forthebigmodels,weaveragedthelast20checkpoints. We\\nusedbeamsearchwithabeamsizeof4andlengthpenaltyα = 0.6[31]. Thesehyperparameters\\nwerechosenafterexperimentationonthedevelopmentset. Wesetthemaximumoutputlengthduring\\ninferencetoinputlength+50,butterminateearlywhenpossible[31].', 'Table2summarizesourresultsandcomparesourtranslationqualityandtrainingcoststoothermodel\\narchitecturesfromtheliterature. Weestimatethenumberoffloatingpointoperationsusedtotraina\\nmodelbymultiplyingthetrainingtime,thenumberofGPUsused,andanestimateofthesustained\\nsingle-precisionfloating-pointcapacityofeachGPU5.\\n6.2 ModelVariations\\nToevaluatetheimportanceofdifferentcomponentsoftheTransformer,wevariedourbasemodel\\nindifferentways,measuringthechangeinperformanceonEnglish-to-Germantranslationonthe', 'developmentset,newstest2013. Weusedbeamsearchasdescribedintheprevioussection,butno\\ncheckpointaveraging. WepresenttheseresultsinTable3.\\nInTable3rows(A),wevarythenumberofattentionheadsandtheattentionkeyandvaluedimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattentionis0.9BLEUworsethanthebestsetting,qualityalsodropsoffwithtoomanyheads.\\n5Weusedvaluesof2.8,3.7,6.0and9.5TFLOPSforK80,K40,M40andP100,respectively.', '8Table3: VariationsontheTransformerarchitecture. Unlistedvaluesareidenticaltothoseofthebase\\nmodel. AllmetricsareontheEnglish-to-Germantranslationdevelopmentset,newstest2013. Listed\\nperplexitiesareper-wordpiece,accordingtoourbyte-pairencoding,andshouldnotbecomparedto\\nper-wordperplexities.\\ntrain PPL BLEU params\\nN d d h d d P (cid:15)\\nmodel ff k v drop ls steps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n(A)\\n16 32 32 4.91 25.8', '4 128 128 5.00 25.5\\n(A)\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n16 5.16 25.1 58\\n(B)\\n32 5.01 25.4 60\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n(C) 256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n(D)\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positionalembeddinginsteadofsinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nInTable3rows(B),weobservethatreducingtheattentionkeysized hurtsmodelquality. This\\nk', 'k\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunctionthandotproductmaybebeneficial. Wefurtherobserveinrows(C)and(D)that,asexpected,\\nbiggermodelsarebetter,anddropoutisveryhelpfulinavoidingover-fitting.Inrow(E)wereplaceour\\nsinusoidalpositionalencodingwithlearnedpositionalembeddings[8],andobservenearlyidentical\\nresultstothebasemodel.\\n7 Conclusion\\nInthiswork,wepresentedtheTransformer,thefirstsequencetransductionmodelbasedentirelyon', 'attention,replacingtherecurrentlayersmostcommonlyusedinencoder-decoderarchitectureswith\\nmulti-headedself-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-Frenchtranslationtasks,weachieveanewstateoftheart. Intheformertaskourbest\\nmodeloutperformsevenallpreviouslyreportedensembles.', 'Weareexcitedaboutthefutureofattention-basedmodelsandplantoapplythemtoothertasks. We\\nplantoextendtheTransformertoproblemsinvolvinginputandoutputmodalitiesotherthantextand\\ntoinvestigatelocal,restrictedattentionmechanismstoefficientlyhandlelargeinputsandoutputs\\nsuchasimages,audioandvideo. Makinggenerationlesssequentialisanotherresearchgoalsofours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.', 'tensorflow/tensor2tensor.\\nAcknowledgements Wearegratefulto NalKalchbrennerand StephanGouwsfor theirfruitful\\ncomments,correctionsandinspiration.\\n9References\\n[1] JimmyLeiBa,JamieRyanKiros,andGeoffreyEHinton. Layernormalization. arXivpreprint\\narXiv:1607.06450,2016.\\n[2] DzmitryBahdanau,KyunghyunCho,andYoshuaBengio. Neuralmachinetranslationbyjointly\\nlearningtoalignandtranslate. CoRR,abs/1409.0473,2014.\\n[3] DennyBritz,AnnaGoldie,Minh-ThangLuong,andQuocV.Le. Massiveexplorationofneural', 'machinetranslationarchitectures. CoRR,abs/1703.03906,2017.\\n[4] JianpengCheng,LiDong,andMirellaLapata. Longshort-termmemory-networksformachine\\nreading. arXivpreprintarXiv:1601.06733,2016.\\n[5] KyunghyunCho,BartvanMerrienboer,CaglarGulcehre,FethiBougares,HolgerSchwenk,\\nandYoshuaBengio. Learningphraserepresentationsusingrnnencoder-decoderforstatistical\\nmachinetranslation. CoRR,abs/1406.1078,2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv', 'preprintarXiv:1610.02357,2016.\\n[7] JunyoungChung,ÇaglarGülçehre,KyunghyunCho,andYoshuaBengio. Empiricalevaluation\\nofgatedrecurrentneuralnetworksonsequencemodeling. CoRR,abs/1412.3555,2014.\\n[8] JonasGehring,MichaelAuli,DavidGrangier,DenisYarats,andYannN.Dauphin. Convolu-\\ntionalsequencetosequencelearning. arXivpreprintarXiv:1705.03122v2,2017.\\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850,2013.', 'arXiv:1308.0850,2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition,pages770–778,2016.\\n[11] SeppHochreiter,YoshuaBengio,PaoloFrasconi,andJürgenSchmidhuber. Gradientflowin\\nrecurrentnets: thedifficultyoflearninglong-termdependencies,2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780,1997.', '9(8):1735–1780,1997.\\n[13] RafalJozefowicz,OriolVinyals,MikeSchuster,NoamShazeer,andYonghuiWu. Exploring\\nthelimitsoflanguagemodeling. arXivpreprintarXiv:1602.02410,2016.\\n[14] ŁukaszKaiserandIlyaSutskever. NeuralGPUslearnalgorithms. InInternationalConference\\nonLearningRepresentations(ICLR),2016.\\n[15] NalKalchbrenner,LasseEspeholt,KarenSimonyan,AaronvandenOord,AlexGraves,andKo-\\nrayKavukcuoglu.Neuralmachinetranslationinlineartime.arXivpreprintarXiv:1610.10099v2,\\n2017.', '2017.\\n[16] YoonKim,CarlDenton,LuongHoang,andAlexanderM.Rush. Structuredattentionnetworks.\\nInInternationalConferenceonLearningRepresentations,2017.\\n[17] DiederikKingmaandJimmyBa. Adam: Amethodforstochasticoptimization. InICLR,2015.\\n[18] OleksiiKuchaievandBorisGinsburg. FactorizationtricksforLSTMnetworks. arXivpreprint\\narXiv:1703.10722,2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen', 'Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130,2017.\\n[20] SamyBengioŁukaszKaiser. Canactivememoryreplaceattention? InAdvancesinNeural\\nInformationProcessingSystems,(NIPS),2016.\\n10[21] Minh-ThangLuong,HieuPham,andChristopherDManning. Effectiveapproachestoattention-\\nbasedneuralmachinetranslation. arXivpreprintarXiv:1508.04025,2015.\\n[22] AnkurParikh,OscarTäckström,DipanjanDas,andJakobUszkoreit. Adecomposableattention', 'model. InEmpiricalMethodsinNaturalLanguageProcessing,2016.\\n[23] RomainPaulus,CaimingXiong,andRichardSocher. Adeepreinforcedmodelforabstractive\\nsummarization. arXivpreprintarXiv:1705.04304,2017.\\n[24] OfirPressandLiorWolf. Usingtheoutputembeddingtoimprovelanguagemodels. arXiv\\npreprintarXiv:1608.05859,2016.\\n[25] RicoSennrich,BarryHaddow,andAlexandraBirch. Neuralmachinetranslationofrarewords\\nwithsubwordunits. arXivpreprintarXiv:1508.07909,2015.', '[26] NoamShazeer,AzaliaMirhoseini,KrzysztofMaziarz,AndyDavis,QuocLe,GeoffreyHinton,\\nandJeffDean. Outrageouslylargeneuralnetworks: Thesparsely-gatedmixture-of-experts\\nlayer. arXivpreprintarXiv:1701.06538,2017.\\n[27] NitishSrivastava,GeoffreyEHinton,AlexKrizhevsky,IlyaSutskever,andRuslanSalakhutdi-\\nnov. Dropout: asimplewaytopreventneuralnetworksfromoverfitting. JournalofMachine\\nLearningResearch,15(1):1929–1958,2014.', 'LearningResearch,15(1):1929–1958,2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. InC.Cortes, N.D.Lawrence, D.D.Lee, M.Sugiyama, andR.Garnett, editors,\\nAdvancesinNeuralInformationProcessingSystems28,pages2440–2448.CurranAssociates,\\nInc.,2015.\\n[29] IlyaSutskever,OriolVinyals,andQuocVVLe. Sequencetosequencelearningwithneural\\nnetworks. InAdvancesinNeuralInformationProcessingSystems,pages3104–3112,2014.', '[30] ChristianSzegedy,VincentVanhoucke,SergeyIoffe,JonathonShlens,andZbigniewWojna.\\nRethinkingtheinceptionarchitectureforcomputervision. CoRR,abs/1512.00567,2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey,MaximKrikun,YuanCao,QinGao,KlausMacherey,etal. Google’sneuralmachine\\ntranslationsystem: Bridgingthegapbetweenhumanandmachinetranslation. arXivpreprint\\narXiv:1609.08144,2016.', 'arXiv:1609.08144,2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forwardconnectionsforneuralmachinetranslation. CoRR,abs/1606.04199,2016.\\n11']\n",
      "29243\n"
     ]
    }
   ],
   "source": [
    "# dividing into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,         # Maximum size of each chunk\n",
    "        chunk_overlap=50,       # Overlap between chunks\n",
    "        length_function=len,    # Function to calculate length\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Possible split points\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "text_chunks = get_text_chunks(text_extracted)\n",
    "print(text_chunks)\n",
    "print(len(text_extracted))\n",
    "\n",
    "#get_text_chunks(text_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpuNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading faiss_cpu-1.9.0-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.9.0-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.2/14.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.9/14.9 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.9 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings and storing\n",
    "def get_vector_store(text_chunks):\n",
    "    embeddings=HuggingFaceBgeEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vector_store=FAISS.from_texts(text_chunks,embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "    \n",
    "get_vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "def create_qa_chain():\n",
    "    prompt_template = \"\"\"\n",
    "    Use the following pieces of context to answer the question. If you cannot find the answer in the context, respond with \"The answer is not available in the context.\" Do not make up or infer any information that is not explicitly stated in the context.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Instructions:\n",
    "    1. Only use information from the provided context\n",
    "    2. If the exact answer is in the context, provide it\n",
    "    3. If the answer is not in the context, say \"The answer is not available in the context\"\n",
    "    4. Keep the answer concise and relevant\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    # llm = Ollama(model=\"llama3.1\", temperature=0.3)  # Load the Llama model\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    # vectorstore = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "\n",
    "    # retriever = vectorstore.as_retriever(\n",
    "    #     search_type=\"similarity\",  # Use similarity search to retrieve relevant chunks\n",
    "    #     search_kwargs={\n",
    "    #         \"k\": 5,                   # Number of relevant chunks to retrieve\n",
    "    #         \"fetch_k\": 15             # Total chunks to fetch\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    # Create a QA chain that combines LLM with the retriever\n",
    "    # qa_chain = RetrievalQA.from_chain_type(\n",
    "    #     llm=llm,\n",
    "    #     chain_type=\"stuff\",  # Use the \"stuff\" type for this chain\n",
    "    #     retriever=retriever,\n",
    "    #     chain_type_kwargs={\n",
    "    #         \"prompt\": PROMPT,\n",
    "    #     },\n",
    "    #     return_source_documents=True  # Optionally return source documents for transparency\n",
    "    # )\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "qa_chain = create_qa_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.conversations = []\n",
    "\n",
    "    def add_conversation(self, user_input, bot_response):\n",
    "        self.conversations.append({'user': user_input, 'bot': bot_response})\n",
    "\n",
    "    def get_context(self):\n",
    "        return \"\\n\".join([f\"User: {conv['user']}\\nBot: {conv['bot']}\" for conv in self.conversations])\n",
    "\n",
    "# Example usage in handle_user_input\n",
    "memory = Memory()\n",
    "\n",
    "def handle_user_input(user_question):\n",
    "    context = memory.get_context()\n",
    "    try:\n",
    "        qa_chain = create_qa_chain()  # Create the QA chain\n",
    "        response = qa_chain.invoke({\n",
    "            \"query\": f\"{context}\\nUser: {user_question}\"  # Include memory context\n",
    "        })\n",
    "        \n",
    "        answer = response.get('result', '').strip()  # Extract the answer\n",
    "        memory.add_conversation(user_question, answer)  # Store the conversation\n",
    "\n",
    "        st.write(\"Reply: \", answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {str(e)}\")\n",
    "        st.write(\"Reply: The answer is not available in the context.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        with pdfplumber.open(pdf) as pdf_reader:\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    for row in table:\n",
    "                        # Filter out None values and join the rest into a string\n",
    "                        filtered_row = [cell for cell in row if cell is not None]\n",
    "                        if filtered_row:  # Check if the filtered row is not empty\n",
    "                            text += \" | \".join(filtered_row) + \"\\n\"  # Join table rows into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for csv\n",
    "import csv\n",
    "def get_csv_text(csv_file):\n",
    "    text=\"\"\n",
    "    with open(csv_file,mode='r',encoding='utf-8') as file:\n",
    "        csv_reader=csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            filtered_row=[cell for cell in row if  cell]\n",
    "            if filtered_row:\n",
    "                text+=\"|\".join(filtered_row) +\"\\n\"\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extract=get_csv_text('D:\\waste for git\\Generative_AI\\Chat_With_Pdf\\Local_Model\\IPL_Ball_by_Ball_2008_2022.csv')\n",
    "#print(text_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxlNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "def get_excel_text(excel_files):\n",
    "    text = \"\"\n",
    "    lis=[]\n",
    "    for excel_file in excel_files: \n",
    "        excel_data = pd.read_excel(excel_file, sheet_name=None)  # Load all sheets\n",
    "        for sheet_name, sheet_data in excel_data.items():\n",
    "            text += f\"Sheet: {sheet_name}\\n\"\n",
    "            for _, row in sheet_data.iterrows():\n",
    "                filtered_row = [str(cell) for cell in row if pd.notna(cell)]\n",
    "                if filtered_row:\n",
    "                    text += \" | \".join(filtered_row) + \"\\n\"\n",
    "            text += \"\\n\"  #\n",
    "            lis.append(Document(page_content = text,metadata={'source' : f\"Sheet {sheet_name}\"}))\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Sheet Sheet1'}, page_content='Sheet: Sheet1\\nif not mystring.strip()\\n | This code snippet is used to check if the string myString is either empty or contains only whitespace characters. In data cleaning, this check can be helpful to identify and handle missing or irrelevant data, which is often necessary before feeding the data into a machine learning model.  Here\\'s how it works:  1.myString.strip(): The strip() method removes any leading or trailing whitespace characters from myString. If the result is an empty string, it indicates that the original string was either completely empty or consisted only of whitespace characters.  2.if not myString.strip()::  The not operator negates the result of myString.strip(). If myString.strip() returns an empty string (which is considered False in Python), the if condition becomes True. This means that if myString is either empty or contains only whitespace characters, the code inside the if block will be executed.\\nisWhitespace = str is type(foo) and not foo.strip()\\nisNotWhitespace = str is type(foo) and not not foo.strip()\\n | These two code snippets are checking whether the variable foo is of type str (a string) and whether it contains only whitespace or not. This can be useful in data cleaning for machine learning to identify and process whitespace entries.  Let\\'s break down both cases:  isWhitespace = str is type(foo) and not foo.strip() This line of code checks if foo is a string and if it contains only whitespace or is empty.  str is type(foo): This ensures that the variable foo is a string. The type(foo) function returns the type of the variable foo, and the condition checks if it\\'s a string (str).  foo.strip(): The strip() method removes leading and trailing whitespace characters from foo. If the result is an empty string, it indicates that foo is either completely empty or consists only of whitespace characters.  not foo.strip(): The not operator checks if the result of foo.strip() is empty (which evaluates to False in Python), meaning foo is either empty or only contains whitespace.  isWhitespace = ...: The result is stored in the variable isWhitespace. If foo is a string and consists only of whitespace or is empty, isWhitespace will be set to True. Otherwise, it will be False.\\nclass weirdstr(str):\\n    def __new__(cls, content):\\n        return str.__new__(cls, content if content is not None else \\'\\')\\n    def __nonzero__(self):\\n        return bool(self.strip())\\n | This code defines a custom string class, weirdstr, which inherits from Python\\'s built-in str class. The class modifies two behaviors: how strings are created and how they are evaluated as \"truthy\" or \"falsy\" in a boolean context.  Let\\'s break it down step by step 1. Class Inheritance and __new__ Method: class weirdstr(str):: This defines a new class called weirdstr that inherits from Python’s built-in str class. It behaves like a regular string but with some custom modifications.  def __new__(cls, content):: The __new__ method is responsible for creating and returning a new instance of the class. In this case, it creates a string instance (str.__new__(cls, content)).  content if content is not None else \\'\\': This logic ensures that if the content is None, it is replaced with an empty string (\\'\\'). This is useful in data cleaning to ensure that a None value is safely converted to an empty string, rather than causing errors or passing through as None. This ensures that any None values in the input data are automatically converted to empty strings, making it easier to handle missing or invalid data in machine learning datasets.  2. __nonzero__ Method (Python 2) / __bool__ (Python 3): def __nonzero__(self):: This method controls how the object is evaluated in a boolean context, like in if statements. In Python 3, this would be written as __bool__.  return bool(self.strip()): This converts the string to a boolean value based on whether it contains non-whitespace characters.  self.strip(): This removes any leading and trailing whitespace from the string. bool(self.strip()): If the stripped string is not empty, it evaluates to True; otherwise, it evaluates to False.\\nnormal = weirdstr(\\'word\\')\\nprint normal, bool(normal)\\n\\nspaces = weirdstr(\\'   \\')\\nprint spaces, bool(spaces)\\n    \\nblank = weirdstr(\\'\\')\\nprint blank, bool(blank)\\n \\nnone = weirdstr(None)print none, bool(none)\\n\\nif not spaces:\\n    print \\'This is a so-called blank string\\'\\n | This code demonstrates how the custom weirdstr class (defined in the previous explanation) works in various cases, such as with normal words, strings with spaces, empty strings, and None values. It also shows how the __nonzero__ (or __bool__ in Python 3) method affects the boolean evaluation of these strings.  Let\\'s break down each section:  1. normal = weirdstr(\\'word\\') and print normal, bool(normal) normal = weirdstr(\\'word\\'): This creates an instance of the weirdstr class with the content \\'word\\'. print normal, bool(normal): The string \\'word\\' contains non-whitespace characters, so it is a \"truthy\" value. The __nonzero__ method (or __bool__ in Python 3) will return True for this string because it has non-whitespace content.\\na = \\'\\'\\nb = \\'   \\'\\na.isspace()\\nb.isspace()\\n | This code uses the isspace() method, which checks if a string contains only whitespace characters.  1. a = \\'\\' and a.isspace() a = \\'\\': The variable a is assigned an empty string. a.isspace(): The isspace() method checks if all characters in the string a are whitespace characters. Since a is an empty string, it has no characters, so isspace() will return False. 2. b = \\' \\' and b.isspace() b = \\' \\': The variable b is assigned a string consisting of three spaces. b.isspace(): The isspace() method checks if all characters in b are whitespace. Since b consists entirely of spaces, isspace() will return True.\\nif mystring and mystring.strip():\\n    print \"not blank string\"\\nelse:\\n    print \"blank string\"\\n | This code checks if mystring is neither empty nor consists solely of whitespace characters. Let\\'s break it down:  1. if mystring and mystring.strip(): mystring: This checks whether mystring is not empty (\\'\\') or None. If mystring contains any value (even just whitespace), this condition will be True.  mystring.strip(): The strip() method removes any leading and trailing whitespace from mystring. If the result is a non-empty string (i.e., it contains non-whitespace characters), this condition will be True.  Combined Check: The condition if mystring and mystring.strip() checks two things:  mystring is not empty or None. mystring.strip() is not an empty string, meaning it contains non-whitespace characters. If both conditions are satisfied, the string is not blank.  2. print \"not blank string\" If both conditions in the if statement are True (i.e., mystring contains non-whitespace characters), this message is printed.  3. else: print \"blank string\" If either:  mystring is empty or None, or mystring.strip() returns an empty string (indicating it only contains whitespace), then the code prints \"blank string\".\\nlines = open(\"my_file.log\", \"r\").readlines()\\n\\nfor line in lines:\\n    if not line.strip():\\n        continue\\n\\n    \\n | This code reads all the lines from a file (my_file.log) and processes each line, skipping any that are empty or contain only whitespace. Here\\'s how it works:  1. lines = open(\"my_file.log\", \"r\").readlines() open(\"my_file.log\", \"r\"): Opens the file my_file.log in read mode (\"r\"). .readlines(): Reads all the lines from the file into a list. Each line in the file becomes an element in the lines list, including the newline characters (\\\\n) at the end of each line. 2. for line in lines: This loop iterates over each line in the list of lines from the file. 3. if not line.strip(): continue line.strip(): The strip() method removes any leading and trailing whitespace (including spaces, tabs, and newline characters) from the line. if not line.strip():: This checks if the stripped line is empty. If the line only contains whitespace (or is empty), line.strip() will return an empty string (\\'\\'), which evaluates to False. continue: If the condition is True (i.e., the line is empty or contains only whitespace), the continue statement is executed. This skips the current iteration of the loop, moving on to the next line without processing the current one.\\ntest1 = \"\"\\ntest2 = \"    \"\\ntest3 = \"    \".strip()\\n\\nprint(bool(test1), bool(test2), bool(test3))\\n         # False      # True       # False\\n\\nif test1:\\n    print(\"test1\") # Not run\\n    \\nif test2:\\n    print(\"test2\") # Run\\n\\nif test3:\\n    print(\"test3\") # Not run\\n\\nif not test1:\\n    print(\"test1\") # Run\\n    \\nif not test2:\\n    print(\"test2\") # Not run\\n\\nif not test3:\\n    print(\"test3\") # Run\\n | This code tests the behavior of empty strings, strings with only spaces, and stripped strings, particularly focusing on their boolean evaluations (True or False). Let’s break it down step by step:  1. String Initialization: test1 = \"\": This is an empty string (\\'\\'). test2 = \" \": This is a string containing four spaces. test3 = \" \".strip(): The strip() method removes all leading and trailing whitespace from the string \" \", resulting in an empty string (\\'\\'). 2. print(bool(test1), bool(test2), bool(test3)) bool(test1): Since test1 is an empty string, it evaluates to False. bool(test2): Even though test2 consists only of spaces, it is not empty, so it evaluates to True. bool(test3): test3 is the result of stripping spaces from \" \", which leaves an empty string (\\'\\'), so it evaluates to False. 3. First Set of if Statements: if test1:: Since test1 is an empty string, the condition evaluates to False, so the code inside this block is not executed.  if test2:: test2 contains spaces and is not empty, so it evaluates to True. The code inside this block is executed, printing \"test2\".  if test3:: test3 is an empty string after the strip(), so it evaluates to False, and the code inside this block is not executed.  4. Second Set of if not Statements: if not test1:: test1 is an empty string, so not test1 evaluates to True. The code inside this block is executed, printing \"test1\".  if not test2:: test2 is not empty (it contains spaces), so not test2 evaluates to False, and the code inside this block is not executed.  if not test3:: test3 is an empty string, so not test3 evaluates to True. The code inside this block is executed, printing \"test3\".\\nfrom termcolor import colored\\n\\nprint(colored(\\'hello\\', \\'red\\'), colored(\\'world\\', \\'green\\'))\\n\\n | This code uses the termcolor library to print text in colored output. The colored() function is used to specify the text and its color.  1. Importing termcolor: from termcolor import colored: This imports the colored function from the termcolor library, which allows you to print colored text in the terminal. 2. print(colored(\\'hello\\', \\'red\\'), colored(\\'world\\', \\'green\\')) colored(\\'hello\\', \\'red\\'): This formats the string \\'hello\\' to be printed in red. colored(\\'world\\', \\'green\\'): This formats the string \\'world\\' to be printed in green. print(...): The two colored strings are printed together, separated by a space, in the specified colors.\\nprint(colored(\\'hello\\', \\'red\\'), colored(\\'world\\', \\'green\\'))\\n | This code uses the termcolor library to print text in different colors to the terminal. Here\\'s how it works:  1. Importing termcolor: from termcolor import colored: This imports the colored function from the termcolor library. The colored function is used to add color to text when printing to the terminal. 2. print(colored(\\'hello\\', \\'red\\'), colored(\\'world\\', \\'green\\')) colored(\\'hello\\', \\'red\\'): This formats the string \\'hello\\' to be printed in red color. The colored function takes two parameters:  The text to color: \\'hello\\' The color name: \\'red\\' colored(\\'world\\', \\'green\\'): This formats the string \\'world\\' to be printed in green color. It also takes two parameters:  The text to color: \\'world\\' The color name: \\'green\\' print(...): The print function outputs both colored strings to the terminal. They are displayed with a space between them.\\nos.system(\\'color\\')\\n | This code uses the os module to execute a command in the terminal to set or change the text color settings.  1. os.system(\\'color\\') os.system(...): The os.system function allows you to run shell commands from within a Python script. It sends the specified command to the operating system to be executed.  \\'color\\': This is the command being executed. In the context of Windows Command Prompt (cmd.exe), the color command is used to configure the text and background color of the terminal.  Without any arguments, color displays a list of available colors and shows the current color settings. If used with arguments (e.g., color 0A), it sets the color of the text and background.\\nfrom colorama import init as colorama_init\\nfrom colorama import Fore\\nfrom colorama import Style\\n\\ncolorama_init()\\n\\nprint(f\"This is {Fore.GREEN}color{Style.RESET_ALL}!\")\\n | This code uses the colorama library to print colored text to the terminal. Here’s a breakdown of how it works:  1. Importing colorama Components: from colorama import init as colorama_init: Imports the init function from colorama and renames it as colorama_init. This function initializes the colorama library, enabling color support for Windows terminals.  from colorama import Fore: Imports the Fore module from colorama, which provides foreground (text) color options.  from colorama import Style: Imports the Style module from colorama, which provides text style options such as reset.  2. Initializing colorama: colorama_init(): Initializes the colorama library. This setup is necessary for colorama to work correctly on Windows platforms, where it ensures color codes are interpreted properly. 3. Printing Colored Text: print(f\"This is {Fore.GREEN}color{Style.RESET_ALL}!\"): {Fore.GREEN}: Applies the green color to the text. Fore.GREEN sets the text color to green. {Style.RESET_ALL}: Resets the text color to the default color after the green text. This ensures that any text following this will not be colored green. The f before the string: Indicates that this is an f-string (formatted string literal), allowing for embedded expressions within the string.\\ndef print_format_table():\\n    \"\"\"\\n    prints table of formatted text format options\\n    \"\"\"\\n    for style in range(8):\\n        for fg in range(30,38):\\n            s1 = \\'\\'\\n            for bg in range(40,48):\\n                format = \\';\\'.join([str(style), str(fg), str(bg)])\\n                s1 += \\'\\\\x1b[%sm %s \\\\x1b[0m\\' % (format, format)\\n            print(s1)\\n        print(\\'\\\\n\\')\\n\\nprint_format_table()\\n | This code defines and executes a function that prints a table of text formatting options using ANSI escape codes. Here\\'s a detailed breakdown:  1. Function Definition: def print_format_table():: Defines a function named print_format_table.  \"\"\" prints table of formatted text format options \"\"\": This docstring describes that the function prints a table showing different text formatting options available using ANSI escape codes.  2. Generating the Formatting Table: for style in range(8):: Iterates over 8 different text styles. The style variable represents ANSI style codes (e.g., normal, bold, underlined).  for fg in range(30, 38):: Iterates over 8 foreground color codes, ranging from 30 to 37. These codes correspond to different text colors.  s1 = \\'\\': Initializes an empty string s1 to accumulate the formatted text for each line.  for bg in range(40, 48):: Iterates over 8 background color codes, ranging from 40 to 47. These codes correspond to different background colors.  format = \\';\\'.join([str(style), str(fg), str(bg)]): Constructs a string representing the ANSI escape code sequence for the current style, foreground color, and background color. For example, 0;31;41 would represent a normal text style with red text and a red background.  s1 += \\'\\\\x1b[%sm %s \\\\x1b[0m\\' % (format, format): Appends a segment to s1 that includes the formatted text:  \\\\x1b[%sm: Starts the text formatting using the ANSI escape sequence. %s: The format string is inserted here to apply the specific style and colors. \\\\x1b[0m: Resets the formatting to default. print(s1): Prints the formatted string s1 for the current combination of styles and colors.  print(\\'\\\\n\\'): Prints a newline to separate different style sections.\\nCRED = \\'\\\\033[91m\\'\\nCEND = \\'\\\\033[0m\\'\\nprint(CRED + \"Error, does not compute!\" + CEND)\\n | This code demonstrates how to use ANSI escape codes to print colored text in the terminal. Here’s a detailed breakdown:  1. Defining Color Codes: CRED = \\'\\\\033[91m\\': This variable is set to the ANSI escape code for bright red text. The \\\\033 (or \\\\e) introduces the escape sequence, [91m specifies the bright red color.  CEND = \\'\\\\033[0m\\': This variable is set to the ANSI escape code for resetting text formatting to default. It ensures that any text following this code is displayed in the terminal’s default color and style.  2. Printing Colored Text: print(CRED + \"Error, does not compute!\" + CEND): CRED: Applies the bright red color to the text. \"Error, does not compute!\": The text to be printed in red. CEND: Resets the text color to default after the message is printed.\\nx = 0\\nfor i in range(24):\\n  colors = \"\"\\n  for j in range(5):\\n    code = str(x+j)\\n    colors = colors + \"\\\\33[\" + code + \"m\\\\\\\\33[\" + code + \"m\\\\033[0m \"\\n  print(colors)\\n  x = x + 5\\n | This code prints a sequence of colored text segments using ANSI escape codes to demonstrate different color codes in the terminal. Here’s a detailed breakdown:  1. Initialization: x = 0: Initializes the variable x to 0. This variable is used to control the starting color code in each iteration of the loop. 2. Outer Loop: for i in range(24):: Loops 24 times, but the loop variable i is not used within the loop.  colors = \"\": Initializes an empty string colors for accumulating color-formatted text in each iteration of the outer loop.  3. Inner Loop: for j in range(5):: Loops 5 times for each iteration of the outer loop. The loop variable j is used to adjust the color code within the current range.  code = str(x + j): Calculates the current color code by adding j to x, and converts it to a string. This generates color codes from x to x + 4.  colors = colors + \"\\\\33[\" + code + \"m\\\\\\\\33[\" + code + \"m\\\\033[0m \":  \\\\33[: Starts the ANSI escape sequence. code + \"m\": Specifies the color code. \\\\\\\\33[: This seems to be a mistake; it should be \\\\33[ to properly format the escape code. \\\\033[0m: Resets the text formatting to default. \" \": Adds a space after each color segment. 4. Print and Update: print(colors): Prints the accumulated colors string for the current row of color codes.  x = x + 5: Updates x by adding 5, which adjusts the starting color code for the next row.\\nimport os\\n\\n# System call\\nos.system(\"\")\\n\\n# Class of different styles\\nclass style():\\n    BLACK = \\'\\\\033[30m\\'\\n    RED = \\'\\\\033[31m\\'\\n    GREEN = \\'\\\\033[32m\\'\\n    YELLOW = \\'\\\\033[33m\\'\\n    BLUE = \\'\\\\033[34m\\'\\n    MAGENTA = \\'\\\\033[35m\\'\\n    CYAN = \\'\\\\033[36m\\'\\n    WHITE = \\'\\\\033[37m\\'\\n    UNDERLINE = \\'\\\\033[4m\\'\\n    RESET = \\'\\\\033[0m\\'\\n\\nprint(style.YELLOW + \"Hello, World!\")\\n | This code demonstrates how to use ANSI escape codes to apply text styles and colors in the terminal. Here’s a breakdown of the code:  1. System Call: import os: Imports the os module, which provides a way to interact with the operating system.  os.system(\"\"): Executes an empty system command. This line is essentially a no-op and does not affect the rest of the code.  2. Class Definition for Styles: class style():: Defines a class named style. This class contains class-level variables for various ANSI escape codes used to format text.  BLACK = \\'\\\\033[30m\\': Defines the ANSI escape code for black text. RED = \\'\\\\033[31m\\': Defines the ANSI escape code for red text. GREEN = \\'\\\\033[32m\\': Defines the ANSI escape code for green text. YELLOW = \\'\\\\033[33m\\': Defines the ANSI escape code for yellow text. BLUE = \\'\\\\033[34m\\': Defines the ANSI escape code for blue text. MAGENTA = \\'\\\\033[35m\\': Defines the ANSI escape code for magenta text. CYAN = \\'\\\\033[36m\\': Defines the ANSI escape code for cyan text. WHITE = \\'\\\\033[37m\\': Defines the ANSI escape code for white text. UNDERLINE = \\'\\\\033[4m\\': Defines the ANSI escape code for underlined text. RESET = \\'\\\\033[0m\\': Defines the ANSI escape code for resetting text formatting to default. 3. Printing Colored Text: print(style.YELLOW + \"Hello, World!\"): style.YELLOW: Applies the yellow color to the text. \"Hello, World!\": The text to be printed. style.RESET: Although not included in the print statement, it is often used to reset the color to default after applying a color.\\nfrom sty import fg, bg, ef, rs\\n\\nfoo = fg.red + \\'This is red text!\\' + fg.rs\\nbar = bg.blue + \\'This has a blue background!\\' + bg.rs\\nbaz = ef.italic + \\'This is italic text\\' + rs.italic\\nqux = fg(201) + \\'This is pink text using 8bit colors\\' + fg.rs\\nqui = fg(255, 10, 10) + \\'This is red text using 24bit colors.\\' + fg.rs\\n\\n# Add custom colors:\\n\\nfrom sty import Style, RgbFg\\n\\nfg.orange = Style(RgbFg(255, 150, 50))\\n\\nbuf = fg.orange + \\'Yay, Im orange.\\' + fg.rs\\n\\nprint(foo, bar, baz, qux, qui, buf, sep=\\'\\\\n\\')\\n | This code uses the sty library to apply various text styles and colors to output in the terminal. Here\\'s a detailed breakdown:  1. Importing sty Components: from sty import fg, bg, ef, rs: fg: Module for foreground (text) colors. bg: Module for background colors. ef: Module for text effects (like bold, italic). rs: Module for resetting styles. 2. Applying Styles and Colors: foo = fg.red + \\'This is red text!\\' + fg.rs:  fg.red: Applies red color to the text. \\'This is red text!\\': The text to be styled. fg.rs: Resets the text color to default after the message. bar = bg.blue + \\'This has a blue background!\\' + bg.rs:  bg.blue: Applies a blue background to the text. \\'This has a blue background!\\': The text to be styled. bg.rs: Resets the background color to default after the message. baz = ef.italic + \\'This is italic text\\' + rs.italic:  ef.italic: Applies italic formatting to the text. \\'This is italic text\\': The text to be styled. rs.italic: Resets the italic formatting to default after the message. qux = fg(201) + \\'This is pink text using 8bit colors\\' + fg.rs:  fg(201): Applies an 8-bit color (color code 201, which is pink) to the text. \\'This is pink text using 8bit colors\\': The text to be styled. fg.rs: Resets the foreground color to default after the message. qui = fg(255, 10, 10) + \\'This is red text using 24bit colors.\\' + fg.rs:  fg(255, 10, 10): Applies a 24-bit RGB color (light red) to the text. \\'This is red text using 24bit colors.\\': The text to be styled. fg.rs: Resets the foreground color to default after the message. 3. Adding Custom Colors: from sty import Style, RgbFg: Imports Style and RgbFg for defining custom styles.  fg.orange = Style(RgbFg(255, 150, 50)):  fg.orange: Defines a custom foreground color named orange using the RGB color values (255, 150, 50). buf = fg.orange + \\'Yay, Im orange.\\' + fg.rs:  fg.orange: Applies the custom orange color to the text. \\'Yay, Im orange.\\': The text to be styled. fg.rs: Resets the foreground color to default after the message. 4. Printing Output: print(foo, bar, baz, qux, qui, buf, sep=\\'\\\\n\\'): foo, bar, baz, qux, qui, buf: Variables containing styled text. sep=\\'\\\\n\\': Prints each text variable on a new line.\\nfrom rich import print\\nprint(\"[red]Color[/] in the [bold magenta]Terminal[/]!\")\\n | This code uses the rich library to print styled text in the terminal with color and formatting. Here’s a breakdown of the code:  1. Importing rich Module: from rich import print: Imports the print function from the rich library. rich is a Python library for rich text and beautiful formatting in the terminal. 2. Printing Styled Text: print(\"[red]Color[/] in the [bold magenta]Terminal[/]!\"): [red]Color[/]: Applies red color to the text \"Color\". The [red] tag starts the red color formatting, and [/] resets the formatting back to default. in the [bold magenta]Terminal[/]!: Applies bold and magenta color to the text \"Terminal\". The [bold magenta] tag starts bold and magenta color formatting, and [/] resets the formatting back to default.\\ndef colored(r, g, b, text):\\n    return f\"\\\\033[38;2;{r};{g};{b}m{text}\\\\033[0m\"\\n | This code defines a function to apply 24-bit RGB color formatting to text using ANSI escape codes. Here’s a detailed breakdown:  1. Function Definition: def colored(r, g, b, text):: Defines a function named colored that takes four parameters: r: The red component of the color (0-255). g: The green component of the color (0-255). b: The blue component of the color (0-255). text: The text to be colored. 2. Color Formatting: return f\"\\\\033[38;2;{r};{g};{b}m{text}\\\\033[0m\": \\\\033[38;2;{r};{g};{b}m: This is the ANSI escape code for 24-bit RGB color. \\\\033: Introduces the escape sequence. 38;2: Indicates that RGB color formatting is being used. {r};{g};{b}: Inserts the RGB values into the escape code. m: Ends the color code. {text}: Inserts the text to be colored. \\\\033[0m: Resets the text formatting to default after the colored text.\\ntext = \\'Hello, World!\\'\\ncolored_text = colored(255, 0, 0, text)\\nprint(colored_text)\\n\\nprint(colored(255, 0, 0, \\'Hello, World!\\'))\\n | This code demonstrates how to use the colored function to apply 24-bit RGB color formatting to text and print it. Here\\'s a breakdown:  1. Defining Text and Coloring: text = \\'Hello, World!\\': Assigns the string \\'Hello, World!\\' to the variable text.  colored_text = colored(255, 0, 0, text):  Calls the colored function with RGB values (255, 0, 0) and the text variable. colored(255, 0, 0, text): Applies red color (RGB: 255, 0, 0) to the text \\'Hello, World!\\'. Stores the resulting colored text in the variable colored_text. 2. Printing Colored Text: print(colored_text):  Prints the colored_text variable, which contains the red-colored version of \\'Hello, World!\\'. print(colored(255, 0, 0, \\'Hello, World!\\')):  Calls the colored function directly with RGB values (255, 0, 0) and the text \\'Hello, World!\\'. Prints the result directly without storing it in a variable.\\ntext = colored(255, 0, 0, \\'Hello, \\') + colored(0, 255, 0, \\'World\\')\\nprint(text)\\n | This code demonstrates how to use the colored function to apply different colors to different parts of a string and then print the resulting text. Here’s a breakdown:  1. Coloring Portions of Text: colored(255, 0, 0, \\'Hello, \\'):  Applies the red color (RGB: 255, 0, 0) to the text \\'Hello, \\'. The colored function returns the red-colored string with ANSI escape codes. colored(0, 255, 0, \\'World\\'):  Applies the green color (RGB: 0, 255, 0) to the text \\'World\\'. The colored function returns the green-colored string with ANSI escape codes. text = colored(255, 0, 0, \\'Hello, \\') + colored(0, 255, 0, \\'World\\'):  Concatenates the red-colored \\'Hello, \\' with the green-colored \\'World\\'. Stores the combined colored text in the variable text.\\nfrom blessings import Terminal\\n\\nt = Terminal()\\nprint t.red(\\'This is red.\\')\\nprint t.bold_bright_red_on_black(\\'Bright red on black\\')\\n | This code utilizes the blessings library to apply terminal text formatting and colors. Here\\'s a breakdown of how it works:  1. Importing blessings: from blessings import Terminal: Imports the Terminal class from the blessings library, which provides a way to style terminal output with colors and effects. 2. Creating a Terminal Object: t = Terminal(): Creates an instance of the Terminal class and assigns it to the variable t. This object will be used to format and style text. 3. Printing Styled Text: print t.red(\\'This is red.\\'):  t.red(\\'This is red.\\'): t.red: Applies red color to the text \\'This is red.\\'. \\'This is red.\\': The text to be styled. print: Outputs the red-colored text to the terminal. print t.bold_bright_red_on_black(\\'Bright red on black\\'):  t.bold_bright_red_on_black(\\'Bright red on black\\'): t.bold_bright_red_on_black: Applies bright red text with a black background to the text \\'Bright red on black\\'. \\'Bright red on black\\': The text to be styled. print: Outputs the styled text to the terminal.\\nprint t.on_green(\\' \\')\\n | This code snippet uses the blessings library to apply a background color to a space character, effectively demonstrating how to set a background color in the terminal.  1. Printing Background Color: print t.on_green(\\' \\'): t.on_green(\\' \\'): t.on_green: Applies a green background color to the text. \\' \\': The text to be displayed is a single space character. print: Outputs the space with a green background to the terminal.\\nwith t.location(0, 5):\\n    print t.on_yellow(\\' \\')\\n | This code uses the blessings library to print a space character with a yellow background at a specific location in the terminal. Here’s how it works:  1. Using t.location: with t.location(0, 5):: t.location(x, y): This context manager sets the cursor position in the terminal to the coordinates (0, 5), where x is the column and y is the row. with: Ensures that the cursor position is set temporarily for the enclosed code block and returns to its original position afterward. 2. Printing Styled Text: print t.on_yellow(\\' \\'): t.on_yellow(\\' \\'): t.on_yellow: Applies a yellow background color to the text. \\' \\': The text to be displayed is a single space character. print: Outputs the space with a yellow background at the specified cursor location.\\nprint \\'{t.clear_eol}You just cleared a {t.bold}whole{t.normal} line!\\'.format(t=t)\\n | This code uses the blessings library to print a formatted message with terminal text styling and control codes. Here’s a detailed breakdown:  1. Using t.clear_eol: {t.clear_eol}: t.clear_eol: This method is from the blessings library and clears from the current cursor position to the end of the line. This is useful for removing any remaining text or formatting that extends beyond the intended output. 2. Applying Text Formatting: {t.bold} and {t.normal}: {t.bold}: Applies bold text formatting. {t.normal}: Resets text formatting to normal (non-bold). .format(t=t): The .format(t=t) method is used to insert the t object into the string placeholders. This allows for dynamic insertion of the blessings formatting codes into the output string. 3. Printing the Formatted Message: print \\'{t.clear_eol}You just cleared a {t.bold}whole{t.normal} line!\\'.format(t=t): \\'{t.clear_eol}You just cleared a {t.bold}whole{t.normal} line!\\': {t.clear_eol}: Clears from the cursor position to the end of the line. {t.bold}: Makes the text \"whole\" bold. {t.normal}: Resets the text formatting after \"whole\". .format(t=t): Formats the string by substituting t into the placeholders for formatting codes. print: Outputs the formatted string to the terminal.\\n# Pure Python 3.x demo, 256 colors\\n# Works with bash under Linux and MacOS\\n\\nfg = lambda text, color: \"\\\\33[38;5;\" + str(color) + \"m\" + text + \"\\\\33[0m\"\\nbg = lambda text, color: \"\\\\33[48;5;\" + str(color) + \"m\" + text + \"\\\\33[0m\"\\n\\ndef print_six(row, format, end=\"\\\\n\"):\\n    for col in range(6):\\n        color = row*6 + col - 2\\n        if color>=0:\\n            text = \"{:3d}\".format(color)\\n            print (format(text,color), end=\" \")\\n        else:\\n            print(end=\"    \")   # four spaces\\n    print(end=end)\\n\\nfor row in range(0, 43):\\n    print_six(row, fg, \" \")\\n    print_six(row, bg)\\n\\n# Simple usage: print(fg(\"text\", 160))\\n | This code demonstrates how to print text with 256 colors in the terminal using ANSI escape codes. It works in bash environments on Linux and macOS. Here\\'s a breakdown:  1. Lambda Functions for Color Formatting: fg = lambda text, color: \"\\\\33[38;5;\" + str(color) + \"m\" + text + \"\\\\33[0m\":  fg: A lambda function to apply foreground (text) color. \\\\33[38;5;: ANSI escape code for 256-color foreground text. str(color): Inserts the color code. m: Ends the color code for text. text: The text to be colored. \\\\33[0m: Resets the text color to default. bg = lambda text, color: \"\\\\33[48;5;\" + str(color) + \"m\" + text + \"\\\\33[0m\":  bg: A lambda function to apply background color. \\\\33[48;5;: ANSI escape code for 256-color background. str(color): Inserts the color code. m: Ends the color code for background. text: The text to be colored. \\\\33[0m: Resets the background color to default. 2. Function to Print Colored Text: def print_six(row, format, end=\"\\\\n\"):: print_six: A function to print 6 columns of colored text.  row: Determines the color row.  format: The lambda function (either fg or bg).  end: The end character for printing, default is newline.  for col in range(6)::  Iterates over 6 columns. color = row*6 + col - 2: Calculates the color index. if color>=0:: Ensures the color index is non-negative. text = \"{:3d}\".format(color): Formats the color index as text. print(format(text,color), end=\" \"): Prints the text with color formatting. else:: Prints spaces if the color index is negative. 3. Printing Color Grids: for row in range(0, 43):: Iterates over rows to print colored text. print_six(row, fg, \" \"): Prints a row of foreground colors. print_six(row, bg): Prints a row of background colors. 4. Simple Usage Example: print(fg(\"text\", 160)): Prints the text \"text\" in color with code 160 using the fg function.\\nfrom colorit import *\\n\\n# Use this to ensure that ColorIt will be usable by certain command line interfaces\\n# Note: This clears the terminal\\ninit_colorit()\\n\\n# Foreground\\nprint(color(\"This text is red\", Colors.red))\\nprint(color(\"This text is orange\", Colors.orange))\\nprint(color(\"This text is yellow\", Colors.yellow))\\nprint(color(\"This text is green\", Colors.green))\\nprint(color(\"This text is blue\", Colors.blue))\\nprint(color(\"This text is purple\", Colors.purple))\\nprint(color(\"This text is white\", Colors.white))\\n\\n# Background\\nprint(background(\"This text has a background that is red\", Colors.red))\\nprint(background(\"This text has a background that is orange\", Colors.orange))\\nprint(background(\"This text has a background that is yellow\", Colors.yellow))\\nprint(background(\"This text has a background that is green\", Colors.green))\\nprint(background(\"This text has a background that is blue\", Colors.blue))\\nprint(background(\"This text has a background that is purple\", Colors.purple))\\nprint(background(\"This text has a background that is white\", Colors.white))\\n\\n# Custom\\nprint(color(\"This color has a custom grey text color\", (150, 150, 150)))\\nprint(background(\"This color has a custom grey background\", (150, 150, 150)))\\n\\n# Combination\\nprint(\\n    background(\\n        color(\"This text is blue with a white background\", Colors.blue), Colors.white\\n    )\\n)\\n\\n# If you are using Windows Command Line, this is so that it doesn\\'t close immediately\\ninput()\\n | This code uses the colorit library to format terminal text with different foreground and background colors. Here’s a breakdown:  1. Initializing colorit: init_colorit(): Initializes the colorit library and clears the terminal to ensure that color formatting will be properly displayed in various command-line interfaces. 2. Printing Foreground Colors: print(color(\"This text is red\", Colors.red)): color(\"This text is red\", Colors.red): Uses the color function to set the text color to red. Similarly, other colors are applied: orange, yellow, green, blue, purple, and white. 3. Printing Background Colors: print(background(\"This text has a background that is red\", Colors.red)): background(\"This text has a background that is red\", Colors.red): Uses the background function to set the background color to red. Similarly, other background colors are applied: orange, yellow, green, blue, purple, and white. 4. Custom Colors: print(color(\"This color has a custom grey text color\", (150, 150, 150))):  color(\"This color has a custom grey text color\", (150, 150, 150)): Applies a custom grey text color using RGB values (150, 150, 150). print(background(\"This color has a custom grey background\", (150, 150, 150))):  background(\"This color has a custom grey background\", (150, 150, 150)): Applies a custom grey background color using RGB values (150, 150, 150). 5. Combining Foreground and Background Colors: print(background(color(\"This text is blue with a white background\", Colors.blue), Colors.white)): color(\"This text is blue with a white background\", Colors.blue): Applies a blue text color. background(..., Colors.white): Applies a white background to the blue text. 6. Preventing Command Line Closure on Windows: input(): input(): Keeps the terminal window open in Windows command line until the user presses Enter. This prevents the terminal from closing immediately after executing the script.\\nimport ctypes\\n\\n# Constants from the Windows API\\nSTD_OUTPUT_HANDLE = -11\\nFOREGROUND_RED    = 0x0004 # text color contains red.\\n\\ndef get_csbi_attributes(handle):\\n    # Based on IPython\\'s winconsole.py, written by Alexander Belchenko\\n    import struct\\n    csbi = ctypes.create_string_buffer(22)\\n    res = ctypes.windll.kernel32.GetConsoleScreenBufferInfo(handle, csbi)\\n    assert res\\n\\n    (bufx, bufy, curx, cury, wattr,\\n    left, top, right, bottom, maxx, maxy) = struct.unpack(\"hhhhHhhhhhh\", csbi.raw)\\n    return wattr\\n\\n\\nhandle = ctypes.windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE)\\nreset = get_csbi_attributes(handle)\\n\\nctypes.windll.kernel32.SetConsoleTextAttribute(handle, FOREGROUND_RED)\\nprint \"Cherry on top\"\\nctypes.windll.kernel32.SetConsoleTextAttribute(handle, reset)\\n | This code snippet demonstrates how to use the Windows API via the ctypes library to change the color of the text output in the Windows console.  1. Constants and Functions: STD_OUTPUT_HANDLE = -11:  Represents the handle for the standard output (stdout) in the Windows console. FOREGROUND_RED = 0x0004:  A constant that sets the text color to red using the Windows API. 2. Getting and Setting Console Attributes: get_csbi_attributes(handle):  A function that retrieves the current console screen buffer attributes. ctypes.create_string_buffer(22): Creates a buffer to hold the console screen buffer information (22 bytes). ctypes.windll.kernel32.GetConsoleScreenBufferInfo(handle, csbi): Calls the Windows API to get the console screen buffer info. struct.unpack(\"hhhhHhhhhhh\", csbi.raw): Unpacks the buffer data into individual attributes. wattr contains the current console text attributes. handle = ctypes.windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE):  Retrieves the handle for the standard output using the Windows API. reset = get_csbi_attributes(handle):  Saves the current text attributes to restore later. ctypes.windll.kernel32.SetConsoleTextAttribute(handle, FOREGROUND_RED):  Changes the text color to red using the Windows API. print \"Cherry on top\":  Prints the text \"Cherry on top\" in red color to the console. ctypes.windll.kernel32.SetConsoleTextAttribute(handle, reset):  Resets the text color to the original attributes saved earlier.\\ndef enable():\\n    HEADER = \\'\\\\033[95m\\'\\n    OKBLUE = \\'\\\\033[94m\\'\\n    OKGREEN = \\'\\\\033[92m\\'\\n    WARNING = \\'\\\\033[93m\\'\\n    FAIL = \\'\\\\033[91m\\'\\n    ENDC = \\'\\\\033[0m\\'\\n    BOLD = \"\\\\033[1m\"\\n\\ndef disable():\\n    HEADER = \\'\\'\\n    OKBLUE = \\'\\'\\n    OKGREEN = \\'\\'\\n    WARNING = \\'\\'\\n    FAIL = \\'\\'\\n    ENDC = \\'\\'\\n\\ndef infog(msg):\\n    print(OKGREEN + msg + ENDC)\\n\\ndef info(msg):\\n    print(OKBLUE + msg + ENDC)\\n\\ndef warn(msg):\\n    print(WARNING + msg + ENDC)\\n\\ndef err(msg):\\n    print(FAIL + msg + ENDC)\\n\\nenable()\\n | This code provides functions to print messages in the terminal with different colors and styles, useful for enhancing the readability of console output. Here’s a detailed breakdown:  1. Color and Style Constants: HEADER = \\'\\\\033[95m\\': Magenta text.  OKBLUE = \\'\\\\033[94m\\': Blue text.  OKGREEN = \\'\\\\033[92m\\': Green text.  WARNING = \\'\\\\033[93m\\': Yellow text.  FAIL = \\'\\\\033[91m\\': Red text.  ENDC = \\'\\\\033[0m\\': Resets text color to default.  BOLD = \"\\\\033[1m\": Bold text (not used in the current functions).  2. Functions to Print Colored Messages: def infog(msg)::  print(OKGREEN + msg + ENDC): Prints a message (msg) in green color (OKGREEN). def info(msg)::  print(OKBLUE + msg + ENDC): Prints a message (msg) in blue color (OKBLUE). def warn(msg)::  print(WARNING + msg + ENDC): Prints a message (msg) in yellow color (WARNING). def err(msg)::  print(FAIL + msg + ENDC): Prints a message (msg) in red color (FAIL). 3. Enable and Disable Functions: def enable()::  Defines the color and style constants for use in the other functions. This function should be called to activate color output. def disable()::  Sets all color and style constants to empty strings, effectively disabling color output. 4. Calling enable(): enable(): Activates the color and style settings for use in the print functions. Expected Output: When you use the infog, info, warn, and err functions after calling enable(), messages will be printed in the specified colors:  Green for informational messages. Blue for general info. Yellow for warnings. Red for errors.\\nimport log\\nlog.info(\"Hello, World!\")\\nlog.err(\"System Error\")\\n | This code snippet demonstrates how to use a logging module (presumably custom) to print messages with different log levels. Here\\'s the breakdown:  1. Importing the Logging Module: import log: Imports a custom logging module named log. This module is expected to contain various logging functions. 2. Using Logging Functions: log.info(\"Hello, World!\"):  Calls the info function from the log module to print the message \"Hello, World!\". Based on previous code, this function would print messages in blue. log.err(\"System Error\"):  Calls the err function from the log module to print the message \"System Error\". Based on previous code, this function would print messages in red.\\ndef black(text):\\n    print(\\'\\\\033[30m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef red(text):\\n    print(\\'\\\\033[31m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef green(text):\\n    print(\\'\\\\033[32m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef yellow(text):\\n    print(\\'\\\\033[33m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef blue(text):\\n    print(\\'\\\\033[34m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef magenta(text):\\n    print(\\'\\\\033[35m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef cyan(text):\\n    print(\\'\\\\033[36m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\ndef gray(text):\\n    print(\\'\\\\033[90m\\', text, \\'\\\\033[0m\\', sep=\\'\\')\\n\\n\\nblack(\"BLACK\")\\nred(\"RED\")\\ngreen(\"GREEN\")\\nyellow(\"YELLOW\")\\nblue(\"BLACK\")\\nmagenta(\"MAGENTA\")\\ncyan(\"CYAN\")\\ngray(\"GRAY\")\\n | This code defines a set of functions to print text in different colors using ANSI escape codes. Each function sets the text color and resets it to default after printing.  1. Color Functions: black(text):  Prints the given text in black color using the ANSI escape code \\\\033[30m for black. red(text):  Prints the given text in red color using the ANSI escape code \\\\033[31m for red. green(text):  Prints the given text in green color using the ANSI escape code \\\\033[32m for green. yellow(text):  Prints the given text in yellow color using the ANSI escape code \\\\033[33m for yellow. blue(text):  Prints the given text in blue color using the ANSI escape code \\\\033[34m for blue. magenta(text):  Prints the given text in magenta color using the ANSI escape code \\\\033[35m for magenta. cyan(text):  Prints the given text in cyan color using the ANSI escape code \\\\033[36m for cyan. gray(text):  Prints the given text in gray color using the ANSI escape code \\\\033[90m for gray. print(\\'\\\\033[0m\\'):  Resets the text color to default using the ANSI escape code \\\\033[0m. 2. Function Calls: black(\"BLACK\"):  Prints the text \"BLACK\" in black color. red(\"RED\"):  Prints the text \"RED\" in red color. green(\"GREEN\"):  Prints the text \"GREEN\" in green color. yellow(\"YELLOW\"):  Prints the text \"YELLOW\" in yellow color. blue(\"BLUE\"):  Prints the text \"BLUE\" in blue color. magenta(\"MAGENTA\"):  Prints the text \"MAGENTA\" in magenta color. cyan(\"CYAN\"):  Prints the text \"CYAN\" in cyan color. gray(\"GRAY\"):  Prints the text \"GRAY\" in gray color.\\nformatters = {\\n    \\'RED\\': \\'\\\\033[91m\\',\\n    \\'GREEN\\': \\'\\\\033[92m\\',\\n    \\'END\\': \\'\\\\033[0m\\',\\n}\\n\\nprint(\\'Master is currently {RED}red{END}!\\'.format(**formatters))\\nprint(\\'Help make master {GREEN}green{END} again!\\'.format(**formatters))\\n\\n | This code snippet demonstrates how to use ANSI escape codes for colored terminal output with string formatting. It uses a dictionary to manage color codes and apply them to text via string formatting.  1. Color Formatters: formatters Dictionary: \\'RED\\': \\'\\\\033[91m\\': Defines the color red for text. \\'GREEN\\': \\'\\\\033[92m\\': Defines the color green for text. \\'END\\': \\'\\\\033[0m\\': Resets the text color to the default. 2. Formatted Printing: print(\\'Master is currently {RED}red{END}!\\'.format(**formatters)):  {RED}: Placeholder for the red color code. {END}: Placeholder for resetting the color. The output will print \"Master is currently red!\" where \"red\" is colored in red. print(\\'Help make master {GREEN}green{END} again!\\'.format(**formatters)):  {GREEN}: Placeholder for the green color code. {END}: Placeholder for resetting the color. The output will print \"Help make master green again!\" where \"green\" is colored in green.\\nclass PrintInColor:\\n    RED = \\'\\\\033[91m\\'\\n    GREEN = \\'\\\\033[92m\\'\\n    YELLOW = \\'\\\\033[93m\\'\\n    LIGHT_PURPLE = \\'\\\\033[94m\\'\\n    PURPLE = \\'\\\\033[95m\\'\\n    END = \\'\\\\033[0m\\'\\n\\n    @classmethod\\n    def red(cls, s, **kwargs):\\n        print(cls.RED + s + cls.END, **kwargs)\\n\\n    @classmethod\\n    def green(cls, s, **kwargs):\\n        print(cls.GREEN + s + cls.END, **kwargs)\\n\\n    @classmethod\\n    def yellow(cls, s, **kwargs):\\n        print(cls.YELLOW + s + cls.END, **kwargs)\\n\\n    @classmethod\\n    def lightPurple(cls, s, **kwargs):\\n        print(cls.LIGHT_PURPLE + s + cls.END, **kwargs)\\n\\n    @classmethod\\n    def purple(cls, s, **kwargs):\\n        print(cls.PURPLE + s + cls.END, **kwargs)\\n | This code defines a class PrintInColor that provides methods to print text in different colors using ANSI escape codes. Each method formats the text with a specific color and prints it.  1. Color Constants: RED = \\'\\\\033[91m\\': Red text color. GREEN = \\'\\\\033[92m\\': Green text color. YELLOW = \\'\\\\033[93m\\': Yellow text color. LIGHT_PURPLE = \\'\\\\033[94m\\': Light purple text color. PURPLE = \\'\\\\033[95m\\': Purple text color. END = \\'\\\\033[0m\\': Resets text color to default. 2. Class Methods for Printing Colored Text: @classmethod def red(cls, s, **kwargs)::  print(cls.RED + s + cls.END, **kwargs): Prints the string s in red color. @classmethod def green(cls, s, **kwargs)::  print(cls.GREEN + s + cls.END, **kwargs): Prints the string s in green color. @classmethod def yellow(cls, s, **kwargs)::  print(cls.YELLOW + s + cls.END, **kwargs): Prints the string s in yellow color. @classmethod def lightPurple(cls, s, **kwargs)::  print(cls.LIGHT_PURPLE + s + cls.END, **kwargs): Prints the string s in light purple color. @classmethod def purple(cls, s, **kwargs)::  print(cls.PURPLE + s + cls.END, **kwargs): Prints the string s in purple color.\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "#excel_extract=get_excel_text([r\"D:\\waste for git\\Generative_AI\\Chat_With_Pdf\\Local_Model\\file_new 1.xlsx\"])\n",
    "\n",
    "print(excel_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RecursiveCharacterTextSplitter(chunk_size = 200,chunk_overlap = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = rc.split_documents(documents=excel_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FAISS.from_documents(documents=docs,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = fa.as_retriever(search_type=\"mmr\",\n",
    "                search_kwargs={'k': 10, 'lambda_mult': 0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46342"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excel_extract[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Sheet Sheet1'}, page_content='colorama_init()'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='black(\"BLACK\")\\nred(\"RED\")\\ngreen(\"GREEN\")\\nyellow(\"YELLOW\")\\nblue(\"BLACK\")\\nmagenta(\"MAGENTA\")\\ncyan(\"CYAN\")\\ngray(\"GRAY\")'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='an empty string colors for accumulating color-formatted text in each iteration of the outer loop.  3. Inner Loop: for j in range(5):: Loops 5 times for each iteration of the outer loop. The loop'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='def colored(r, g, b, text):\\n    return f\"\\\\033[38;2;{r};{g};{b}m{text}\\\\033[0m\"'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='from termcolor import colored'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='command-line interfaces. 2. Printing Foreground Colors: print(color(\"This text is red\", Colors.red)): color(\"This text is red\", Colors.red): Uses the color function to set the text color to red.'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content=\"print(colored('hello', 'red'), colored('world', 'green'))\"),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content=\"the colored function with RGB values (255, 0, 0) and the text variable. colored(255, 0, 0, text): Applies red color (RGB: 255, 0, 0) to the text 'Hello, World!'. Stores the resulting colored text in\"),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='text \"GREEN\" in green color. yellow(\"YELLOW\"):  Prints the text \"YELLOW\" in yellow color. blue(\"BLUE\"):  Prints the text \"BLUE\" in blue color. magenta(\"MAGENTA\"):  Prints the text \"MAGENTA\" in'),\n",
       " Document(metadata={'source': 'Sheet Sheet1'}, page_content='from colorit import *')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = r.invoke(\"Colorma\")\n",
    "# len(data),data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-pptx\n",
      "  Using cached python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from python-pptx) (10.4.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Using cached XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from python-pptx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from python-pptx) (4.12.2)\n",
      "Using cached python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: XlsxWriter, python-docx, python-pptx\n",
      "Successfully installed XlsxWriter-3.2.0 python-docx-1.1.2 python-pptx-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-pptx python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def get_ppt_text(ppt_file):\n",
    "    \"\"\"Extract text from PowerPoint files efficiently.\"\"\"\n",
    "    documents = []\n",
    "    prs = Presentation(ppt_file)\n",
    "    \n",
    "    all_slide_texts = []  # Accumulate all slide texts here\n",
    "    for i, slide in enumerate(prs.slides):\n",
    "        slide_text_parts = []  # Accumulate text per slide\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:  # Optimized check for text\n",
    "                slide_text_parts.append(shape.text)  # Add text content\n",
    "        \n",
    "        slide_text = \"\\n\".join(slide_text_parts)\n",
    "        all_slide_texts.append(f\"Slide {i+1}:\\n{slide_text}\")\n",
    "        \n",
    "        # Create a Document for each slide\n",
    "        documents.append(Document(page_content=slide_text, metadata={'source': f'PowerPoint Slide {i+1}'}))\n",
    "    \n",
    "    # Combine all slide texts into a single string\n",
    "    full_text = \"\\n\\n\".join(all_slide_texts)\n",
    "    \n",
    "    return full_text, documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Slide 1:\\n\\n\\n\\n\\nInternship Presentation\\nSubmitted by:\\nAnkita\\nIntern – Software Development Trainee\\nCO20309\\nCSE 4th year\\nManager – Mr. Rajul Goyal\\xa0\\n\\n\\n\\n\\nSlide 2:\\n\\nTesting Xperts\\xa0(Tx) proudly stands as a global leader in Digital\\xa0Assurance and Quality Engineering, firmly positioned among the five\\xa0largest providers worldwide. With headquarters strategically located in\\xa0Pennsylvania, USA, and London, UK, Testing Xperts(Tx) maintain a dynamic network of\\xa0offices and delivery centers across the United States, Canada, the United\\xa0Kingdom,\\xa0the Netherlands, South Africa,\\xa0UAE, India, and Singapore.\\x0b\\x0bAt\\xa0Testing Xperts, our expertise shines through a comprehensive\\xa0spectrum of Digital Assurance and Quality Engineering services that\\xa0encompass QA/Test Advisory, as well as Functional and Non-Functional\\xa0testing. These services are impeccably tailored to meet the demands of\\xa0Next Gen technologies. Our specialization extends seamlessly to\\xa0Automation, Digital, DevOps, Agile, Web, Mobility, AI/ML, RPA,\\xa0Blockchain, IOT, and Big Data, reflecting our commitment to a holistic\\xa0range of capabilities.\\n\\n\\n\\ufeffCompany\\'s Overview\\n\\n\\n\\n\\n\\n\\nSlide 3:\\n\\n\\n\\n\\ufeffGoals and Objectives\\n\\n\\n\\n\\n\\n\\nSlide 4:\\n\\n\\n\\n\\ufeffAGENDA\\n\\n\\n\\nPhase 1: Foundations\\n\\u2003\\u2003\\u20031. Python Programming\\n\\u2003\\u2003\\u20032. Numpy and Pandas\\n\\u2003\\u2003\\u20033. Supervised Learning\\n\\u2003\\u2003\\u20034. Unsupervised Learning\\n\\u2003\\u2003\\u20035. Deep Learning\\n\\u2003\\u2003\\u20036. Artificial Neural Network\\n\\u2003\\u2003\\u20037. Convolutional Neural Network\\n\\u2003\\xa0 \\xa0 \\xa0 \\xa0 8. Natural Language Processing\\n\\u2003\\xa0 \\xa0 \\xa0 \\xa0 9. Recurrent Neural Network\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa010. Long Short-Term Memory\\xa0\\n\\nPhase 2: Project showcase\\n\\u2003\\u2003\\xa0 \\xa0 1.\\xa0 Problem Statement\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 2.\\xa0 Project Introduction\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 3. Flow Diagram of Project development\\n\\n\\n\\n\\nSlide 5:\\n\\n\\ufeffPython Programming\\nPython\\xa0is a\\xa0high-level,\\xa0general-purpose programming language. Its design\\xa0philosophy emphasizes\\xa0code readability\\xa0with use of\\xa0significant indentation. Python is\\xa0dynamically typed and\\xa0garbage-collected. It supports multiple\\xa0programming paradigms, including\\xa0structured\\xa0(particularly\\xa0procedural),\\n\\xa0object-oriented\\xa0and\\xa0functional programming.\\n\\nTopics covered:\\nPython Basics\\nFunctions\\nData Structures\\nModules\\nErrors and Exceptions\\nClasses\\n\\n\\nSlide 6:\\n\\n\\ufeffNumpy\\xa0\\nNumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\\n\\n\\n\\n\\n\\n\\n\\nSlide 7:\\n\\n\\n\\n\\n\\n\\nSlide 8:\\n\\n\\ufeffPandas\\nPandas\\xa0is a fast, powerful, flexible and easy to use open-source data analysis and manipulation tool, built on top of the\\xa0Python\\xa0programming language.\\n\\n\\n\\nSlide 9:\\n\\n\\n\\n\\n\\nSlide 10:\\n\\nSupervised Learning\\nSupervised learning is a process of providing input data as well as correct output data to the machine learning model. The aim of a supervised learning algorithm is to\\xa0find a mapping function to map the input variable(x) with the output variable(y).\\n\\n\\n\\nSlide 11:\\n\\nUnsupervised Learning\\nUnsupervised learning is a machine learning technique in which models are not supervised using training dataset. Instead, models itself find the hidden patterns and insights from the given data. It can be compared to learning which takes place in the human brain while learning new things.\\n\\n\\n\\nSlide 12:\\n\\nDeep Learning\\nDeep learning is a branch of\\xa0machine learning that\\xa0is made up of a neural network with three or more layers:\\nInput layer:\\xa0Data enters through the input layer.\\nHidden layers:\\xa0Hidden layers process and transport data to other layers.\\nOutput layer:\\xa0The final result\\xa0 or prediction is made in the output layer.\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 13:\\n\\n\\xa0 Artificial Neural Network\\n\\xa0 \\xa0Artificial Neural Network (ANN) is a computational model inspired by the human brain\\'s neural structure. It consists of interconnected nodes organized into layers. Nodes process information using weighted connections, and each layer has an activation function introducing non-linearity. ANNs are trained on labeled data, adjusting connection weights through backpropagation to learn patterns and make predictions. They are widely used in machine learning, particularly in tasks such as image recognition, natural language processing, and pattern recognition.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 14:\\n\\n\\xa0 Convolutional Neural Network\\n\\n\\xa0 Convolutional Neural Network (CNN) is a specialized type of neural network designed for visual data processing, such as images and videos. It uses convolutional layers to automatically learn hierarchical features from input data. CNNs have proven effective in tasks like image classification, object detection, and image segmentation, making them a key technology in computer vision applications.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 15:\\n\\n\\xa0 \\xa0 \\xa0Natural Language Preprocessing\\n\\n\\xa0 Natural Language Processing (NLP) is a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language. It involves the use of computational techniques to process and analyze natural language data, such as text and speech, with the goal of understanding the meaning behind the language.\\n\\n\\xa0 NLP is used in a wide range of applications, including machine translation, sentiment analysis, speech recognition, chatbots, and text classification. Some common techniques used in NLP include:\\nTokenization: the process of breaking text into individual words or phrases.\\nPart-of-speech tagging: the process of labeling each word in a sentence with its grammatical part of speech.\\nNamed entity recognition: the process of identifying and categorizing named entities, such as people, places, and organizations, in text.\\nSentiment analysis: the process of determining the sentiment of a piece of text, such as whether it is positive, negative, or neutral.\\nText classification: the process of categorizing text into predefined categories or topics.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 16:\\n\\n\\xa0 Recurrent Neural Network\\n\\n\\xa0 A Recurrent Neural Network (RNN) is a type of artificial neural network designed to process sequential and temporal data. Unlike traditional feedforward neural networks, RNNs have connections that form a directed cycle, allowing them to maintain and utilize information about previous inputs in the sequence. This architecture makes RNNs well-suited for tasks involving sequences, such as natural language processing, speech recognition, and time series prediction. However, RNNs can face challenges in capturing long-term dependencies, leading to the development of more advanced architectures like Long Short-Term Memory (LSTM) networks.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 17:\\n\\n\\xa0 \\xa0 \\xa0Long Short Term Memory\\n\\n\\xa0\\xa0LSTM stands for Long Short-Term Memory. It is a type of recurrent neural network (RNN)\\xa0\\xa0architecture, specifically designed to address the vanishing gradient problem which can occur\\xa0when training traditional RNNs.\\n\\nTraditional RNNs have a tendency to forget information from earlier time steps when processing sequences of data. This limitation can hinder their ability to effectively learn and remember long-range dependencies within sequential data. LSTMs address this problem by introducing a more complex memory cell structure that allows them to selectively retain or forget information over long periods of time. This is achieved through the use of multiple gates (input, forget, and output gates) that control the flow of information within the network. These gates regulate the flow of information by deciding what information to keep or discard at each time step.\\n\\nThe key components of an LSTM cell include:\\n\\nCell State: This represents the \"memory\" of the cell and can carry information across many time steps. The cell state is controlled by the gates, which modulate the flow of information into and out of the cell state.\\nInput Gate: This gate controls the flow of new information into the cell state. It decides which values from the input should be updated and added to the cell state.\\nForget Gate: This gate controls the flow of information out of the cell state. It decides which information should be discarded from the cell state.\\nOutput Gate: This gate controls the flow of information from the cell state to the output. It decides what information from the cell state should be exposed as the output of the LSTM cell.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSlide 18:\\n\\n\\n\\n\\nCodeDocGen: Intelligent Documentation Generation for Software Projects\\n\\nSlide 19:\\n\\n\\n\\n\\n\\nThe goal is to develop a Generative AI (GenAI) solution capable of analyzing existing codebases or user prompts and generating a comprehensive list of required documentation tailored to the specific project, such as an ERP solution or a CMS. The GenAI model will leverage advanced natural language processing techniques to understand the codebase or prompt and produce structured documentation covering various aspects, including architecture, functionality, APIs, and usage guidelines. Furthermore, the solution will adopt an incremental approach, continuously refining and expanding the generated documentation based on user feedback and evolving project requirements. This project aims to streamline the documentation process, enhance project understanding, and improve collaboration among development teams.\\nProblem Statement\\n\\nSlide 20:\\n\\n\\n\\nThe problem statement outlines the goal of developing a Generative AI (GenAI) solution for automating the documentation process of software projects. This solution aims to analyze existing codebases or user prompts and generate comprehensive documentation tailored to specific projects, such as Enterprise Resource Planning (ERP) solutions or Content Management Systems (CMS).\\xa0The GenAI model will utilize advanced natural language processing (NLP) techniques to understand the codebase or user prompts. It will then produce structured documentation covering various aspects of the project, including:\\n\\nArchitecture: Describing the overall structure and design of the software system, including components, modules, and their relationships.\\nFunctionality: Detailing the features and functionalities implemented in the software, including how they work and their intended purposes.\\nAPIs: Documenting the application programming interfaces (APIs) provided by the software, including their endpoints, parameters, and usage instructions.\\nUsage Guidelines: Providing guidelines and best practices for using the software, including configuration options, deployment instructions, and recommended workflows.\\n\\nProject Introduction\\n\\nSlide 21:\\n\\n\\nFlow Diagram of Project\\n\\nSlide 22:\\n\\n\\nOur Project Phases\\n\\n\\n\\n\\nData Building\\nCreate user stories\\xa0\\n\\n\\n\\n\\n\\n\\u2003Model implementation\\nInterface Designing\\nBusiness Purpose\\nRNN, LSTM, NLP, Generative AI\\nFrontend and Backend\\xa0\\nBusiness analysis\\n\\n\\n\\nSlide 23:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ufeffTHANK YOU',\n",
       " [Document(metadata={'source': 'PowerPoint Slide 1'}, page_content='\\n\\n\\n\\nInternship Presentation\\nSubmitted by:\\nAnkita\\nIntern – Software Development Trainee\\nCO20309\\nCSE 4th year\\nManager – Mr. Rajul Goyal\\xa0\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 2'}, page_content=\"\\nTesting Xperts\\xa0(Tx) proudly stands as a global leader in Digital\\xa0Assurance and Quality Engineering, firmly positioned among the five\\xa0largest providers worldwide. With headquarters strategically located in\\xa0Pennsylvania, USA, and London, UK, Testing Xperts(Tx) maintain a dynamic network of\\xa0offices and delivery centers across the United States, Canada, the United\\xa0Kingdom,\\xa0the Netherlands, South Africa,\\xa0UAE, India, and Singapore.\\x0b\\x0bAt\\xa0Testing Xperts, our expertise shines through a comprehensive\\xa0spectrum of Digital Assurance and Quality Engineering services that\\xa0encompass QA/Test Advisory, as well as Functional and Non-Functional\\xa0testing. These services are impeccably tailored to meet the demands of\\xa0Next Gen technologies. Our specialization extends seamlessly to\\xa0Automation, Digital, DevOps, Agile, Web, Mobility, AI/ML, RPA,\\xa0Blockchain, IOT, and Big Data, reflecting our commitment to a holistic\\xa0range of capabilities.\\n\\n\\n\\ufeffCompany's Overview\\n\\n\\n\\n\\n\"),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 3'}, page_content='\\n\\n\\n\\ufeffGoals and Objectives\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 4'}, page_content='\\n\\n\\n\\ufeffAGENDA\\n\\n\\n\\nPhase 1: Foundations\\n\\u2003\\u2003\\u20031. Python Programming\\n\\u2003\\u2003\\u20032. Numpy and Pandas\\n\\u2003\\u2003\\u20033. Supervised Learning\\n\\u2003\\u2003\\u20034. Unsupervised Learning\\n\\u2003\\u2003\\u20035. Deep Learning\\n\\u2003\\u2003\\u20036. Artificial Neural Network\\n\\u2003\\u2003\\u20037. Convolutional Neural Network\\n\\u2003\\xa0 \\xa0 \\xa0 \\xa0 8. Natural Language Processing\\n\\u2003\\xa0 \\xa0 \\xa0 \\xa0 9. Recurrent Neural Network\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa010. Long Short-Term Memory\\xa0\\n\\nPhase 2: Project showcase\\n\\u2003\\u2003\\xa0 \\xa0 1.\\xa0 Problem Statement\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 2.\\xa0 Project Introduction\\n\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 3. Flow Diagram of Project development\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 5'}, page_content='\\n\\ufeffPython Programming\\nPython\\xa0is a\\xa0high-level,\\xa0general-purpose programming language. Its design\\xa0philosophy emphasizes\\xa0code readability\\xa0with use of\\xa0significant indentation. Python is\\xa0dynamically typed and\\xa0garbage-collected. It supports multiple\\xa0programming paradigms, including\\xa0structured\\xa0(particularly\\xa0procedural),\\n\\xa0object-oriented\\xa0and\\xa0functional programming.\\n\\nTopics covered:\\nPython Basics\\nFunctions\\nData Structures\\nModules\\nErrors and Exceptions\\nClasses\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 6'}, page_content='\\n\\ufeffNumpy\\xa0\\nNumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 7'}, page_content='\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 8'}, page_content='\\n\\ufeffPandas\\nPandas\\xa0is a fast, powerful, flexible and easy to use open-source data analysis and manipulation tool, built on top of the\\xa0Python\\xa0programming language.\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 9'}, page_content='\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 10'}, page_content='\\nSupervised Learning\\nSupervised learning is a process of providing input data as well as correct output data to the machine learning model. The aim of a supervised learning algorithm is to\\xa0find a mapping function to map the input variable(x) with the output variable(y).\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 11'}, page_content='\\nUnsupervised Learning\\nUnsupervised learning is a machine learning technique in which models are not supervised using training dataset. Instead, models itself find the hidden patterns and insights from the given data. It can be compared to learning which takes place in the human brain while learning new things.\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 12'}, page_content='\\nDeep Learning\\nDeep learning is a branch of\\xa0machine learning that\\xa0is made up of a neural network with three or more layers:\\nInput layer:\\xa0Data enters through the input layer.\\nHidden layers:\\xa0Hidden layers process and transport data to other layers.\\nOutput layer:\\xa0The final result\\xa0 or prediction is made in the output layer.\\n\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 13'}, page_content=\"\\n\\xa0 Artificial Neural Network\\n\\xa0 \\xa0Artificial Neural Network (ANN) is a computational model inspired by the human brain's neural structure. It consists of interconnected nodes organized into layers. Nodes process information using weighted connections, and each layer has an activation function introducing non-linearity. ANNs are trained on labeled data, adjusting connection weights through backpropagation to learn patterns and make predictions. They are widely used in machine learning, particularly in tasks such as image recognition, natural language processing, and pattern recognition.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 14'}, page_content='\\n\\xa0 Convolutional Neural Network\\n\\n\\xa0 Convolutional Neural Network (CNN) is a specialized type of neural network designed for visual data processing, such as images and videos. It uses convolutional layers to automatically learn hierarchical features from input data. CNNs have proven effective in tasks like image classification, object detection, and image segmentation, making them a key technology in computer vision applications.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 15'}, page_content='\\n\\xa0 \\xa0 \\xa0Natural Language Preprocessing\\n\\n\\xa0 Natural Language Processing (NLP) is a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language. It involves the use of computational techniques to process and analyze natural language data, such as text and speech, with the goal of understanding the meaning behind the language.\\n\\n\\xa0 NLP is used in a wide range of applications, including machine translation, sentiment analysis, speech recognition, chatbots, and text classification. Some common techniques used in NLP include:\\nTokenization: the process of breaking text into individual words or phrases.\\nPart-of-speech tagging: the process of labeling each word in a sentence with its grammatical part of speech.\\nNamed entity recognition: the process of identifying and categorizing named entities, such as people, places, and organizations, in text.\\nSentiment analysis: the process of determining the sentiment of a piece of text, such as whether it is positive, negative, or neutral.\\nText classification: the process of categorizing text into predefined categories or topics.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 16'}, page_content='\\n\\xa0 Recurrent Neural Network\\n\\n\\xa0 A Recurrent Neural Network (RNN) is a type of artificial neural network designed to process sequential and temporal data. Unlike traditional feedforward neural networks, RNNs have connections that form a directed cycle, allowing them to maintain and utilize information about previous inputs in the sequence. This architecture makes RNNs well-suited for tasks involving sequences, such as natural language processing, speech recognition, and time series prediction. However, RNNs can face challenges in capturing long-term dependencies, leading to the development of more advanced architectures like Long Short-Term Memory (LSTM) networks.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 17'}, page_content='\\n\\xa0 \\xa0 \\xa0Long Short Term Memory\\n\\n\\xa0\\xa0LSTM stands for Long Short-Term Memory. It is a type of recurrent neural network (RNN)\\xa0\\xa0architecture, specifically designed to address the vanishing gradient problem which can occur\\xa0when training traditional RNNs.\\n\\nTraditional RNNs have a tendency to forget information from earlier time steps when processing sequences of data. This limitation can hinder their ability to effectively learn and remember long-range dependencies within sequential data. LSTMs address this problem by introducing a more complex memory cell structure that allows them to selectively retain or forget information over long periods of time. This is achieved through the use of multiple gates (input, forget, and output gates) that control the flow of information within the network. These gates regulate the flow of information by deciding what information to keep or discard at each time step.\\n\\nThe key components of an LSTM cell include:\\n\\nCell State: This represents the \"memory\" of the cell and can carry information across many time steps. The cell state is controlled by the gates, which modulate the flow of information into and out of the cell state.\\nInput Gate: This gate controls the flow of new information into the cell state. It decides which values from the input should be updated and added to the cell state.\\nForget Gate: This gate controls the flow of information out of the cell state. It decides which information should be discarded from the cell state.\\nOutput Gate: This gate controls the flow of information from the cell state to the output. It decides what information from the cell state should be exposed as the output of the LSTM cell.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 18'}, page_content='\\n\\n\\n\\nCodeDocGen: Intelligent Documentation Generation for Software Projects'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 19'}, page_content='\\n\\n\\n\\n\\nThe goal is to develop a Generative AI (GenAI) solution capable of analyzing existing codebases or user prompts and generating a comprehensive list of required documentation tailored to the specific project, such as an ERP solution or a CMS. The GenAI model will leverage advanced natural language processing techniques to understand the codebase or prompt and produce structured documentation covering various aspects, including architecture, functionality, APIs, and usage guidelines. Furthermore, the solution will adopt an incremental approach, continuously refining and expanding the generated documentation based on user feedback and evolving project requirements. This project aims to streamline the documentation process, enhance project understanding, and improve collaboration among development teams.\\nProblem Statement'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 20'}, page_content='\\n\\n\\nThe problem statement outlines the goal of developing a Generative AI (GenAI) solution for automating the documentation process of software projects. This solution aims to analyze existing codebases or user prompts and generate comprehensive documentation tailored to specific projects, such as Enterprise Resource Planning (ERP) solutions or Content Management Systems (CMS).\\xa0The GenAI model will utilize advanced natural language processing (NLP) techniques to understand the codebase or user prompts. It will then produce structured documentation covering various aspects of the project, including:\\n\\nArchitecture: Describing the overall structure and design of the software system, including components, modules, and their relationships.\\nFunctionality: Detailing the features and functionalities implemented in the software, including how they work and their intended purposes.\\nAPIs: Documenting the application programming interfaces (APIs) provided by the software, including their endpoints, parameters, and usage instructions.\\nUsage Guidelines: Providing guidelines and best practices for using the software, including configuration options, deployment instructions, and recommended workflows.\\n\\nProject Introduction'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 21'}, page_content='\\n\\nFlow Diagram of Project'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 22'}, page_content='\\n\\nOur Project Phases\\n\\n\\n\\n\\nData Building\\nCreate user stories\\xa0\\n\\n\\n\\n\\n\\n\\u2003Model implementation\\nInterface Designing\\nBusiness Purpose\\nRNN, LSTM, NLP, Generative AI\\nFrontend and Backend\\xa0\\nBusiness analysis\\n\\n'),\n",
       "  Document(metadata={'source': 'PowerPoint Slide 23'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ufeffTHANK YOU')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ppt_text(\"ppt_report.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (10.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_text(image_files):\n",
    "    \"\"\"Extract text from image files using OCR.\"\"\"\n",
    "    text = \"\"\n",
    "    documents = []\n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            image = Image.open(image_file)\n",
    "            image_text = pytesseract.image_to_string(image)\n",
    "            cleaned_text = ' '.join(image_text.split())  # Remove extra whitespace\n",
    "            text += cleaned_text + \"\\n\"\n",
    "            documents.append(Document(page_content=cleaned_text, metadata={'source': f\"Image: {image_file}\"}))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_file}: {str(e)}\")\n",
    "    return text, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image S: name 'Image' is not defined\n",
      "Error processing image c: name 'Image' is not defined\n",
      "Error processing image r: name 'Image' is not defined\n",
      "Error processing image e: name 'Image' is not defined\n",
      "Error processing image e: name 'Image' is not defined\n",
      "Error processing image n: name 'Image' is not defined\n",
      "Error processing image s: name 'Image' is not defined\n",
      "Error processing image h: name 'Image' is not defined\n",
      "Error processing image o: name 'Image' is not defined\n",
      "Error processing image t: name 'Image' is not defined\n",
      "Error processing image  : name 'Image' is not defined\n",
      "Error processing image (: name 'Image' is not defined\n",
      "Error processing image 1: name 'Image' is not defined\n",
      "Error processing image 3: name 'Image' is not defined\n",
      "Error processing image ): name 'Image' is not defined\n",
      "Error processing image .: name 'Image' is not defined\n",
      "Error processing image p: name 'Image' is not defined\n",
      "Error processing image n: name 'Image' is not defined\n",
      "Error processing image g: name 'Image' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_text(\"Screenshot (13).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\mohammed riyaz\\anaconda3\\envs\\rag\\lib\\site-packages (from pytesseract) (10.4.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtesseract\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tesseract \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tesseract'"
     ]
    }
   ],
   "source": [
    "import tesseract\n",
    "print(tesseract --version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TesseractNotFoundError",
     "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\pytesseract\\pytesseract.py:275\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msubprocess_args())\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\subprocess.py:1456\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1458\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScreenshot (13).png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform OCR\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    487\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    488\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 489\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    342\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    350\u001b[0m     }\n\u001b[1;32m--> 352\u001b[0m     run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    355\u001b[0m         return_bytes,\n\u001b[0;32m    356\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mohammed Riyaz\\anaconda3\\envs\\rag\\lib\\site-packages\\pytesseract\\pytesseract.py:280\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n",
      "\u001b[1;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image = Image.open('Screenshot (13).png')\n",
    "\n",
    "# Perform OCR\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
